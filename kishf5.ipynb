{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kishf5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balszeg/deep_learning_kishf5/blob/main/kishf5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swkefJPa4thR"
      },
      "source": [
        "# Installing and building the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wcTptbboI1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4450d5e-718f-4257-e305-cd80f4db34bd"
      },
      "source": [
        "# for this homework hyperas will be used\n",
        "!pip3 install hyperas\n",
        "!pip3 install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperas in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.8)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.0.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.7.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (20.0.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert->hyperas) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (50.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiyPYOiz5DR3"
      },
      "source": [
        "Firstly, import the necessary utilites from Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOAKsleeAdqK"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NBQz1Qu5RL9"
      },
      "source": [
        "Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvNZbAFvBnFs"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4KCo9qy5T3l"
      },
      "source": [
        "Setting up the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iewspUMxAtUq"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 50"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vREDs2f_5ZYd"
      },
      "source": [
        "Encoding to one-hot the labels to 1-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHhs1gkFBQuU"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHDHtNLJ5gkH"
      },
      "source": [
        "Setting the datatype to float32 for later purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48uMAMr8X3QC"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLa8Kmok5o35"
      },
      "source": [
        "Normalizing the data between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8UvsefoH30i"
      },
      "source": [
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb0hXFOI5u29"
      },
      "source": [
        "Building and compiling the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F6Mqsb3BaLE"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#the model below based on basic principles and trial-error experiences\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y45-hrw16IgQ"
      },
      "source": [
        "Setting callback function for early stop, if the learning hit the plateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8atJOHniDe2i"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, verbose=0)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oCjsaJ_6aIl"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-mYyhB4Bazs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbe585c-e632-4e3c-e1a3-b0383450e02c"
      },
      "source": [
        "result = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8652 - accuracy: 0.3279 - val_loss: 1.7047 - val_accuracy: 0.3902\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6658 - accuracy: 0.4082 - val_loss: 1.7689 - val_accuracy: 0.3588\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5824 - accuracy: 0.4365 - val_loss: 1.5440 - val_accuracy: 0.4463\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5193 - accuracy: 0.4600 - val_loss: 1.5399 - val_accuracy: 0.4536\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4716 - accuracy: 0.4770 - val_loss: 1.4833 - val_accuracy: 0.4685\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4325 - accuracy: 0.4928 - val_loss: 1.5785 - val_accuracy: 0.4353\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3945 - accuracy: 0.5041 - val_loss: 1.4494 - val_accuracy: 0.4733\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3605 - accuracy: 0.5165 - val_loss: 1.4192 - val_accuracy: 0.4920\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3267 - accuracy: 0.5305 - val_loss: 1.4917 - val_accuracy: 0.4711\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3003 - accuracy: 0.5408 - val_loss: 1.4013 - val_accuracy: 0.5010\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2723 - accuracy: 0.5490 - val_loss: 1.3942 - val_accuracy: 0.5086\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2463 - accuracy: 0.5607 - val_loss: 1.3894 - val_accuracy: 0.5069\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2217 - accuracy: 0.5672 - val_loss: 1.3652 - val_accuracy: 0.5175\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1970 - accuracy: 0.5763 - val_loss: 1.3372 - val_accuracy: 0.5267\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1714 - accuracy: 0.5856 - val_loss: 1.3831 - val_accuracy: 0.5095\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1454 - accuracy: 0.5942 - val_loss: 1.4283 - val_accuracy: 0.5028\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1205 - accuracy: 0.6040 - val_loss: 1.3179 - val_accuracy: 0.5330\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0992 - accuracy: 0.6115 - val_loss: 1.3165 - val_accuracy: 0.5299\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0792 - accuracy: 0.6184 - val_loss: 1.3506 - val_accuracy: 0.5234\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0519 - accuracy: 0.6256 - val_loss: 1.3300 - val_accuracy: 0.5388\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0298 - accuracy: 0.6360 - val_loss: 1.4337 - val_accuracy: 0.5053\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0079 - accuracy: 0.6428 - val_loss: 1.4682 - val_accuracy: 0.5090\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9853 - accuracy: 0.6527 - val_loss: 1.4278 - val_accuracy: 0.5172\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9635 - accuracy: 0.6591 - val_loss: 1.3467 - val_accuracy: 0.5443\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9372 - accuracy: 0.6689 - val_loss: 1.4558 - val_accuracy: 0.4988\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9129 - accuracy: 0.6752 - val_loss: 1.3782 - val_accuracy: 0.5345\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8923 - accuracy: 0.6842 - val_loss: 1.4186 - val_accuracy: 0.5271\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8707 - accuracy: 0.6927 - val_loss: 1.4408 - val_accuracy: 0.5269\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8453 - accuracy: 0.6995 - val_loss: 1.3563 - val_accuracy: 0.5505\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8224 - accuracy: 0.7100 - val_loss: 1.4666 - val_accuracy: 0.5215\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8011 - accuracy: 0.7179 - val_loss: 1.4812 - val_accuracy: 0.5203\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7783 - accuracy: 0.7263 - val_loss: 1.4475 - val_accuracy: 0.5408\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7518 - accuracy: 0.7352 - val_loss: 1.4138 - val_accuracy: 0.5444\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7330 - accuracy: 0.7427 - val_loss: 1.6937 - val_accuracy: 0.5009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKAIP0yP6gPO"
      },
      "source": [
        "Let see the best validation accuracy at this point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap8jnDU-CUEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9bdcc87-9ad9-4da3-f992-ebede8c49fe8"
      },
      "source": [
        "best_val_acc = np.amax(result.history['val_accuracy']) \n",
        "print('The best val_acc:', best_val_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best val_acc: 0.5504999756813049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxiJkAp06rEA"
      },
      "source": [
        "# Optimizin with hyperas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSQLpApL8SSN"
      },
      "source": [
        "For the hyperas it is necessary to change the network in the right format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqYjVQVTtvpB"
      },
      "source": [
        "# firstly, separately downloading the data and building the model\n",
        "# for these a function defined\n",
        "\n",
        "def data():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  \n",
        "  num_classes = 10\n",
        "  \n",
        "  # encoding to one-hot the labels\n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "  \n",
        "  # setting the type to float32\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "\n",
        "  # normalizing between 0-1\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq4KljRet1tP"
      },
      "source": [
        "# defining a function for model creating too\n",
        "\n",
        "def create_model(x_train, y_train, x_test, y_test):\n",
        "    \n",
        "    # swish optimizer will be used, and it has to be coded too\n",
        "    # for that, the code from this site used \n",
        "    # https://stackoverflow.com/questions/53050448/custom-activation-with-parameter\n",
        "    from keras.layers import Layer\n",
        "    from keras import backend as K\n",
        "\n",
        "    class Swish(Layer):\n",
        "        def __init__(self, beta, **kwargs):\n",
        "            super(Swish, self).__init__(**kwargs)\n",
        "            self.beta = K.cast_to_floatx(beta)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            return K.sigmoid(self.beta * inputs) * inputs\n",
        "\n",
        "        def get_config(self):\n",
        "            config = {'beta': float(self.beta)}\n",
        "            base_config = super(Swish, self).get_config()\n",
        "            return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "        def compute_output_shape(self, input_shape):\n",
        "            return input_shape\n",
        "    \n",
        "    # the different choices given for the hyperas\n",
        "    # the number of neurons on the dense layers\n",
        "    n_layer1 = {{choice([256, 512, 1024])}}\n",
        "    n_layer2 = {{choice([256, 512, 1024])}}\n",
        "    n_layer3 = {{choice([256, 512, 1024])}}\n",
        "\n",
        "    # the dropout and its measure\n",
        "    dropout_1 = {{uniform(0, 0.5)}}\n",
        "    dropout_2 = {{uniform(0, 0.5)}}\n",
        "    dropout_3 = {{uniform(0, 0.5)}}\n",
        "\n",
        "    # the activation functions\n",
        "    act = {{choice(['relu', 'leakyrelu', 'swish'])}}\n",
        "\n",
        "    # the optimizers\n",
        "    optim = {{choice(['rmsprop', 'adam', 'sgd'])}}\n",
        "\n",
        "    # the batch sizes\n",
        "    n_batch = {{choice([64, 128, 256])}}\n",
        "    print(\"the model's hyperparameters:\", n_layer1, n_layer2, dropout_1, dropout_2, act, optim, n_batch)\n",
        "    \n",
        "    # handling the activation choices\n",
        "    if act == 'relu':\n",
        "        activation = keras.layers.ReLU()\n",
        "    elif act == 'leakyrelu':\n",
        "        activation = keras.layers.LeakyReLU()\n",
        "    elif act == 'swish':\n",
        "        activation = Swish(beta=0.3)\n",
        "    \n",
        "    # defining where to use dropout\n",
        "    model = Sequential()\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(n_layer1))\n",
        "    model.add(activation)\n",
        "    model.add(Dropout(dropout_1))\n",
        "    model.add(Dense(n_layer2))\n",
        "    model.add(activation)\n",
        "    model.add(Dropout(dropout_2))\n",
        "    model.add(Dense(n_layer3))\n",
        "    model.add(activation)\n",
        "    model.add(Dropout(dropout_3))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer=optim,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # setting early stopp\n",
        "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)]\n",
        "    \n",
        "    # training the model\n",
        "    result = model.fit(x_train, y_train,\n",
        "              batch_size=n_batch,\n",
        "              epochs=50,\n",
        "              verbose=2,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)\n",
        "\n",
        "    \n",
        "    # printing the best accuracy from the epochs\n",
        "    best_val_acc = np.amax(result.history['val_accuracy']) \n",
        "    print('the best val_acc:', best_val_acc)\n",
        "    \n",
        "    # creating a log file where the training can be later seen\n",
        "    with open('hyperas-cifar10-log.csv', 'a') as csv_file:\n",
        "      csv_file.write(str(n_layer1) + ';')\n",
        "      csv_file.write(str(n_layer2) + ';')\n",
        "      csv_file.write(str(n_layer3) + ';')\n",
        "      csv_file.write(str(dropout_1) + ';')\n",
        "      csv_file.write(str(dropout_2) + ';')\n",
        "      csv_file.write(str(dropout_3) + ';')\n",
        "      csv_file.write(str(act) + ';')\n",
        "      csv_file.write(str(optim) + ';')\n",
        "      csv_file.write(str(n_batch) + ';')\n",
        "      csv_file.write(str(best_val_acc) + '\\n')\n",
        "\n",
        "    return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVqBg3jQ_etc"
      },
      "source": [
        "Initailazing the log file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxMW4gCQGe2y"
      },
      "source": [
        "# setting up its header\n",
        "with open('hyperas-cifar10-log.csv', 'w') as csv_file:\n",
        "  csv_file.write('n_layer1' + ';')\n",
        "  csv_file.write('n_layer2' + ';')\n",
        "  csv_file.write('n_layer3' + ';')\n",
        "  csv_file.write('dropout_1' + ';')\n",
        "  csv_file.write('dropout_2' + ';')\n",
        "  csv_file.write('dropout_3' + ';')\n",
        "  csv_file.write('act' + ';')\n",
        "  csv_file.write('optim' + ';')\n",
        "  csv_file.write('n_batch' + ';')\n",
        "  csv_file.write('best_val_acc' + '\\n')\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD1Iirrg_t4u"
      },
      "source": [
        "**Important step**, the user has to download the current .ipynb from and upload right back to the files. The reason is that, the hyperas cannot use the defined above choices, because cannot reach the source. The colab store it somewhere else, with this download-upload come around we can still use hyperas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NifrPxCsNcc"
      },
      "source": [
        "# importing the utilities for hyperas\n",
        "import hyperas\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgu3AV31eVu6"
      },
      "source": [
        "Starting the optimizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJDODM7tHB66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e216fac-cc56-4ed1-87d5-4a67a6941739"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                          data=data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=100,\n",
        "                                          notebook_name='kishf5',\n",
        "                                          trials=Trials())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import cifar10\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Flatten, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Layer\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import hyperas\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import seaborn as sns\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'n_layer1': hp.choice('n_layer1', [256, 512, 1024]),\n",
            "        'n_layer1_1': hp.choice('n_layer1_1', [256, 512, 1024]),\n",
            "        'n_layer1_2': hp.choice('n_layer1_2', [256, 512, 1024]),\n",
            "        'dropout_1': hp.uniform('dropout_1', 0, 0.5),\n",
            "        'dropout_1_1': hp.uniform('dropout_1_1', 0, 0.5),\n",
            "        'dropout_1_2': hp.uniform('dropout_1_2', 0, 0.5),\n",
            "        'act': hp.choice('act', ['relu', 'leakyrelu', 'swish']),\n",
            "        'optim': hp.choice('optim', ['rmsprop', 'adam', 'sgd']),\n",
            "        'n_batch': hp.choice('n_batch', [64, 128, 256]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
            "  3: \n",
            "  4: num_classes = 10\n",
            "  5: \n",
            "  6: # encoding to one-hot the labels\n",
            "  7: y_train = keras.utils.to_categorical(y_train, num_classes)\n",
            "  8: y_test = keras.utils.to_categorical(y_test, num_classes)\n",
            "  9: \n",
            " 10: # setting the type to float32\n",
            " 11: x_train = x_train.astype('float32')\n",
            " 12: x_test = x_test.astype('float32')\n",
            " 13: \n",
            " 14: # normalizing between 0-1\n",
            " 15: x_train /= 255\n",
            " 16: x_test /= 255\n",
            " 17: \n",
            " 18: \n",
            " 19: \n",
            " 20: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     \n",
            "   4:     # swish optimizer will be used, and it has to be coded too\n",
            "   5:     # for that, the code from this site used \n",
            "   6:     # https://stackoverflow.com/questions/53050448/custom-activation-with-parameter\n",
            "   7: \n",
            "   8:     class Swish(Layer):\n",
            "   9:         def __init__(self, beta, **kwargs):\n",
            "  10:             super(Swish, self).__init__(**kwargs)\n",
            "  11:             self.beta = K.cast_to_floatx(beta)\n",
            "  12: \n",
            "  13:         def call(self, inputs):\n",
            "  14:             return K.sigmoid(self.beta * inputs) * inputs\n",
            "  15: \n",
            "  16:         def get_config(self):\n",
            "  17:             config = {'beta': float(self.beta)}\n",
            "  18:             base_config = super(Swish, self).get_config()\n",
            "  19:             return dict(list(base_config.items()) + list(config.items()))\n",
            "  20: \n",
            "  21:         def compute_output_shape(self, input_shape):\n",
            "  22:             return input_shape\n",
            "  23:     \n",
            "  24:     # the different choices given for the hyperas\n",
            "  25:     # the number of neurons on the dense layers\n",
            "  26:     n_layer1 = space['n_layer1']\n",
            "  27:     n_layer2 = space['n_layer1_1']\n",
            "  28:     n_layer3 = space['n_layer1_2']\n",
            "  29: \n",
            "  30:     # the dropout and its measure\n",
            "  31:     dropout_1 = space['dropout_1']\n",
            "  32:     dropout_2 = space['dropout_1_1']\n",
            "  33:     dropout_3 = space['dropout_1_2']\n",
            "  34: \n",
            "  35:     # the activation functions\n",
            "  36:     act = space['act']\n",
            "  37: \n",
            "  38:     # the optimizers\n",
            "  39:     optim = space['optim']\n",
            "  40: \n",
            "  41:     # the batch sizes\n",
            "  42:     n_batch = space['n_batch']\n",
            "  43:     print(\"the model's hyperparameters:\", n_layer1, n_layer2, dropout_1, dropout_2, act, optim, n_batch)\n",
            "  44:     \n",
            "  45:     # handling the activation choices\n",
            "  46:     if act == 'relu':\n",
            "  47:         activation = keras.layers.ReLU()\n",
            "  48:     elif act == 'leakyrelu':\n",
            "  49:         activation = keras.layers.LeakyReLU()\n",
            "  50:     elif act == 'swish':\n",
            "  51:         activation = Swish(beta=0.3)\n",
            "  52:     \n",
            "  53:     # defining where to use dropout\n",
            "  54:     model = Sequential()\n",
            "  55:     model.add(Flatten())\n",
            "  56:     model.add(Dense(n_layer1))\n",
            "  57:     model.add(activation)\n",
            "  58:     model.add(Dropout(dropout_1))\n",
            "  59:     model.add(Dense(n_layer2))\n",
            "  60:     model.add(activation)\n",
            "  61:     model.add(Dropout(dropout_2))\n",
            "  62:     model.add(Dense(n_layer3))\n",
            "  63:     model.add(activation)\n",
            "  64:     model.add(Dropout(dropout_3))\n",
            "  65:     model.add(Dense(10, activation='softmax'))\n",
            "  66:     \n",
            "  67:     model.compile(optimizer=optim,\n",
            "  68:                   loss='categorical_crossentropy',\n",
            "  69:                   metrics=['accuracy'])\n",
            "  70: \n",
            "  71:     # setting early stopp\n",
            "  72:     callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)]\n",
            "  73:     \n",
            "  74:     # training the model\n",
            "  75:     result = model.fit(x_train, y_train,\n",
            "  76:               batch_size=n_batch,\n",
            "  77:               epochs=50,\n",
            "  78:               verbose=2,\n",
            "  79:               validation_data=(x_test, y_test),\n",
            "  80:               callbacks=callbacks,\n",
            "  81:               shuffle=True)\n",
            "  82: \n",
            "  83:     \n",
            "  84:     # printing the best accuracy from the epochs\n",
            "  85:     best_val_acc = np.amax(result.history['val_accuracy']) \n",
            "  86:     print('the best val_acc:', best_val_acc)\n",
            "  87:     \n",
            "  88:     # creating a log file where the training can be later seen\n",
            "  89:     with open('hyperas-cifar10-log.csv', 'a') as csv_file:\n",
            "  90:       csv_file.write(str(n_layer1) + ';')\n",
            "  91:       csv_file.write(str(n_layer2) + ';')\n",
            "  92:       csv_file.write(str(n_layer3) + ';')\n",
            "  93:       csv_file.write(str(dropout_1) + ';')\n",
            "  94:       csv_file.write(str(dropout_2) + ';')\n",
            "  95:       csv_file.write(str(dropout_3) + ';')\n",
            "  96:       csv_file.write(str(act) + ';')\n",
            "  97:       csv_file.write(str(optim) + ';')\n",
            "  98:       csv_file.write(str(n_batch) + ';')\n",
            "  99:       csv_file.write(str(best_val_acc) + '\\n')\n",
            " 100: \n",
            " 101:     return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}\n",
            " 102: \n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.008909307568613745\n",
            "0.42251493823699554\n",
            "leakyrelu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.0142 - accuracy: 0.2734 - val_loss: 1.8411 - val_accuracy: 0.3524\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.8519 - accuracy: 0.3417 - val_loss: 1.8011 - val_accuracy: 0.3592\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.7941 - accuracy: 0.3668 - val_loss: 1.7640 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7484 - accuracy: 0.3820 - val_loss: 1.7124 - val_accuracy: 0.3905\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7247 - accuracy: 0.3899 - val_loss: 1.6514 - val_accuracy: 0.4281\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.6949 - accuracy: 0.4011 - val_loss: 1.6933 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.6777 - accuracy: 0.4091 - val_loss: 1.6975 - val_accuracy: 0.3846\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.6528 - accuracy: 0.4224 - val_loss: 1.6245 - val_accuracy: 0.4271\n",
            "\n",
            "the best val_acc:\n",
            "0.42809998989105225\n",
            "the model's hyperparameters:\n",
            "256\n",
            "512\n",
            "0.21702063071082567\n",
            "0.34875377644265604\n",
            "relu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            "196/196 - 2s - loss: 2.5821 - accuracy: 0.1410 - val_loss: 2.1769 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.1974 - accuracy: 0.1578 - val_loss: 2.1314 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 2.1302 - accuracy: 0.1938 - val_loss: 2.0678 - val_accuracy: 0.2150\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 2.0921 - accuracy: 0.2112 - val_loss: 2.0408 - val_accuracy: 0.2271\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 2.0442 - accuracy: 0.2338 - val_loss: 1.9141 - val_accuracy: 0.2869\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 2.0164 - accuracy: 0.2425 - val_loss: 2.1184 - val_accuracy: 0.2366\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 2.0009 - accuracy: 0.2520 - val_loss: 1.9254 - val_accuracy: 0.2804\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.9782 - accuracy: 0.2629 - val_loss: 1.9334 - val_accuracy: 0.2746\n",
            "\n",
            "the best val_acc:\n",
            "0.28690001368522644\n",
            "the model's hyperparameters:\n",
            "256\n",
            "1024\n",
            "0.35571237603931743\n",
            "0.2811907528782607\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.1981 - accuracy: 0.2578 - val_loss: 1.8204 - val_accuracy: 0.3658\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.9237 - accuracy: 0.3140 - val_loss: 1.9000 - val_accuracy: 0.3145\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8416 - accuracy: 0.3456 - val_loss: 1.7226 - val_accuracy: 0.3893\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.8112 - accuracy: 0.3551 - val_loss: 1.7299 - val_accuracy: 0.3866\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.8021 - accuracy: 0.3585 - val_loss: 1.7057 - val_accuracy: 0.3993\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.7852 - accuracy: 0.3693 - val_loss: 1.7785 - val_accuracy: 0.3709\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.7815 - accuracy: 0.3684 - val_loss: 1.7338 - val_accuracy: 0.3713\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.7759 - accuracy: 0.3673 - val_loss: 1.6503 - val_accuracy: 0.4081\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.7629 - accuracy: 0.3724 - val_loss: 1.7013 - val_accuracy: 0.3857\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.7539 - accuracy: 0.3775 - val_loss: 1.6739 - val_accuracy: 0.3906\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.7479 - accuracy: 0.3774 - val_loss: 1.6374 - val_accuracy: 0.4193\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 3s - loss: 1.7460 - accuracy: 0.3839 - val_loss: 1.6841 - val_accuracy: 0.4101\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 3s - loss: 1.7345 - accuracy: 0.3847 - val_loss: 1.6425 - val_accuracy: 0.4179\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 3s - loss: 1.7263 - accuracy: 0.3901 - val_loss: 1.6485 - val_accuracy: 0.4195\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 3s - loss: 1.7195 - accuracy: 0.3910 - val_loss: 1.6616 - val_accuracy: 0.4028\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 3s - loss: 1.7148 - accuracy: 0.3938 - val_loss: 1.6501 - val_accuracy: 0.4064\n",
            "\n",
            "Epoch 17/50\n",
            "391/391 - 3s - loss: 1.7101 - accuracy: 0.3964 - val_loss: 1.6525 - val_accuracy: 0.4176\n",
            "\n",
            "the best val_acc:\n",
            "0.4194999933242798\n",
            "the model's hyperparameters:\n",
            "512\n",
            "512\n",
            "0.4987765704119526\n",
            "0.4956006935248156\n",
            "swish\n",
            "adam\n",
            "256\n",
            "Epoch 1/50\n",
            "  3%|▎         | 3/100 [01:30<48:31, 30.01s/it, best loss: -0.42809998989105225]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50430c6f98>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50430c6f98>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50430c6f98>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50430c6f98>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "196/196 - 2s - loss: 2.5252 - accuracy: 0.2127 - val_loss: 1.8501 - val_accuracy: 0.3234\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.0677 - accuracy: 0.2719 - val_loss: 1.7944 - val_accuracy: 0.3662\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 1.9363 - accuracy: 0.3091 - val_loss: 1.7420 - val_accuracy: 0.3826\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.8560 - accuracy: 0.3338 - val_loss: 1.7365 - val_accuracy: 0.3748\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 1.8102 - accuracy: 0.3497 - val_loss: 1.6854 - val_accuracy: 0.4020\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.7797 - accuracy: 0.3629 - val_loss: 1.6913 - val_accuracy: 0.3953\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.7647 - accuracy: 0.3682 - val_loss: 1.6524 - val_accuracy: 0.4137\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.7435 - accuracy: 0.3761 - val_loss: 1.6359 - val_accuracy: 0.4226\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.7327 - accuracy: 0.3831 - val_loss: 1.6064 - val_accuracy: 0.4306\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.7220 - accuracy: 0.3843 - val_loss: 1.6397 - val_accuracy: 0.4192\n",
            "\n",
            "Epoch 11/50\n",
            "196/196 - 2s - loss: 1.7095 - accuracy: 0.3935 - val_loss: 1.5862 - val_accuracy: 0.4370\n",
            "\n",
            "Epoch 12/50\n",
            "196/196 - 2s - loss: 1.7006 - accuracy: 0.3921 - val_loss: 1.5725 - val_accuracy: 0.4436\n",
            "\n",
            "Epoch 13/50\n",
            "196/196 - 2s - loss: 1.6926 - accuracy: 0.3938 - val_loss: 1.5636 - val_accuracy: 0.4414\n",
            "\n",
            "Epoch 14/50\n",
            "196/196 - 2s - loss: 1.6873 - accuracy: 0.3973 - val_loss: 1.5990 - val_accuracy: 0.4369\n",
            "\n",
            "Epoch 15/50\n",
            "196/196 - 2s - loss: 1.6830 - accuracy: 0.3993 - val_loss: 1.5453 - val_accuracy: 0.4512\n",
            "\n",
            "Epoch 16/50\n",
            "196/196 - 2s - loss: 1.6679 - accuracy: 0.4061 - val_loss: 1.5677 - val_accuracy: 0.4394\n",
            "\n",
            "Epoch 17/50\n",
            "196/196 - 2s - loss: 1.6611 - accuracy: 0.4054 - val_loss: 1.5477 - val_accuracy: 0.4460\n",
            "\n",
            "Epoch 18/50\n",
            "196/196 - 2s - loss: 1.6535 - accuracy: 0.4091 - val_loss: 1.5443 - val_accuracy: 0.4475\n",
            "\n",
            "the best val_acc:\n",
            "0.451200008392334\n",
            "the model's hyperparameters:\n",
            "512\n",
            "1024\n",
            "0.39685786811007157\n",
            "0.4182140362909876\n",
            "swish\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            "  4%|▍         | 4/100 [02:01<48:29, 30.31s/it, best loss: -0.451200008392334]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042f0c550>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042f0c550>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042f0c550>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042f0c550>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "196/196 - 2s - loss: 5.7164 - accuracy: 0.1409 - val_loss: 2.7059 - val_accuracy: 0.1296\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.3289 - accuracy: 0.2070 - val_loss: 2.0076 - val_accuracy: 0.2817\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 2.0593 - accuracy: 0.2559 - val_loss: 1.9261 - val_accuracy: 0.3009\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.9693 - accuracy: 0.2898 - val_loss: 2.1275 - val_accuracy: 0.2751\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 1.9376 - accuracy: 0.3049 - val_loss: 1.7633 - val_accuracy: 0.3699\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.8894 - accuracy: 0.3209 - val_loss: 1.8618 - val_accuracy: 0.3289\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.8707 - accuracy: 0.3297 - val_loss: 2.0942 - val_accuracy: 0.2607\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.8479 - accuracy: 0.3438 - val_loss: 1.7663 - val_accuracy: 0.3621\n",
            "\n",
            "the best val_acc:\n",
            "0.3698999881744385\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.10261962796174634\n",
            "0.2133592523277144\n",
            "leakyrelu\n",
            "sgd\n",
            "64\n",
            "Epoch 1/50\n",
            "782/782 - 5s - loss: 1.9458 - accuracy: 0.3036 - val_loss: 1.8043 - val_accuracy: 0.3607\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.7911 - accuracy: 0.3657 - val_loss: 1.7761 - val_accuracy: 0.3588\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7288 - accuracy: 0.3896 - val_loss: 1.7630 - val_accuracy: 0.3829\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.6931 - accuracy: 0.4012 - val_loss: 1.6823 - val_accuracy: 0.4001\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6596 - accuracy: 0.4162 - val_loss: 1.7713 - val_accuracy: 0.3702\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6375 - accuracy: 0.4249 - val_loss: 1.8690 - val_accuracy: 0.3629\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6117 - accuracy: 0.4309 - val_loss: 1.9415 - val_accuracy: 0.3367\n",
            "\n",
            "the best val_acc:\n",
            "0.4000999927520752\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.3845025987312817\n",
            "0.4776618748329053\n",
            "swish\n",
            "rmsprop\n",
            "64\n",
            "Epoch 1/50\n",
            "  6%|▌         | 6/100 [02:53<45:34, 29.09s/it, best loss: -0.451200008392334]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042d547b8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042d547b8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042d547b8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5042d547b8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 6s - loss: 3.9698 - accuracy: 0.1805 - val_loss: 2.0610 - val_accuracy: 0.2439\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 6s - loss: 1.9590 - accuracy: 0.2970 - val_loss: 1.8297 - val_accuracy: 0.3029\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 6s - loss: 1.8756 - accuracy: 0.3267 - val_loss: 1.8251 - val_accuracy: 0.3341\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 6s - loss: 1.8392 - accuracy: 0.3422 - val_loss: 1.7411 - val_accuracy: 0.3809\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 6s - loss: 1.8160 - accuracy: 0.3514 - val_loss: 1.6895 - val_accuracy: 0.3865\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 6s - loss: 1.7921 - accuracy: 0.3611 - val_loss: 1.7286 - val_accuracy: 0.3834\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 6s - loss: 1.7732 - accuracy: 0.3684 - val_loss: 1.7878 - val_accuracy: 0.3718\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 6s - loss: 1.7610 - accuracy: 0.3783 - val_loss: 1.7769 - val_accuracy: 0.3576\n",
            "\n",
            "the best val_acc:\n",
            "0.3865000009536743\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "512\n",
            "0.10549830270553806\n",
            "0.14663551098307936\n",
            "leakyrelu\n",
            "sgd\n",
            "256\n",
            "Epoch 1/50\n",
            "196/196 - 2s - loss: 2.0712 - accuracy: 0.2553 - val_loss: 1.8812 - val_accuracy: 0.3365\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 1.8731 - accuracy: 0.3340 - val_loss: 1.7814 - val_accuracy: 0.3764\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 1.8188 - accuracy: 0.3578 - val_loss: 1.7848 - val_accuracy: 0.3771\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.7798 - accuracy: 0.3719 - val_loss: 1.7645 - val_accuracy: 0.3784\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 1s - loss: 1.7484 - accuracy: 0.3860 - val_loss: 1.7069 - val_accuracy: 0.4097\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.7289 - accuracy: 0.3920 - val_loss: 1.6873 - val_accuracy: 0.4048\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.7079 - accuracy: 0.4027 - val_loss: 1.8689 - val_accuracy: 0.3398\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 1s - loss: 1.6873 - accuracy: 0.4083 - val_loss: 1.6454 - val_accuracy: 0.4239\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.6762 - accuracy: 0.4092 - val_loss: 1.6352 - val_accuracy: 0.4269\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.6610 - accuracy: 0.4153 - val_loss: 1.6329 - val_accuracy: 0.4352\n",
            "\n",
            "Epoch 11/50\n",
            "196/196 - 2s - loss: 1.6466 - accuracy: 0.4215 - val_loss: 1.6382 - val_accuracy: 0.4234\n",
            "\n",
            "Epoch 12/50\n",
            "196/196 - 2s - loss: 1.6358 - accuracy: 0.4268 - val_loss: 1.6247 - val_accuracy: 0.4216\n",
            "\n",
            "Epoch 13/50\n",
            "196/196 - 1s - loss: 1.6247 - accuracy: 0.4341 - val_loss: 1.6086 - val_accuracy: 0.4321\n",
            "\n",
            "the best val_acc:\n",
            "0.4352000057697296\n",
            "the model's hyperparameters:\n",
            "512\n",
            "1024\n",
            "0.3237079338781867\n",
            "0.4079879962997267\n",
            "swish\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            "  8%|▊         | 8/100 [04:06<48:11, 31.42s/it, best loss: -0.451200008392334]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503e740898>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503e740898>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503e740898>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503e740898>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "196/196 - 2s - loss: 6.2530 - accuracy: 0.1439 - val_loss: 4.0683 - val_accuracy: 0.1217\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.3587 - accuracy: 0.2042 - val_loss: 2.4034 - val_accuracy: 0.1787\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 2.0489 - accuracy: 0.2602 - val_loss: 1.9365 - val_accuracy: 0.2959\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.9529 - accuracy: 0.2947 - val_loss: 1.8245 - val_accuracy: 0.3558\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 1.9021 - accuracy: 0.3145 - val_loss: 1.8509 - val_accuracy: 0.3145\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.8660 - accuracy: 0.3283 - val_loss: 1.7816 - val_accuracy: 0.3597\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.8371 - accuracy: 0.3417 - val_loss: 1.6968 - val_accuracy: 0.3969\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.8175 - accuracy: 0.3499 - val_loss: 1.8228 - val_accuracy: 0.3422\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.7877 - accuracy: 0.3630 - val_loss: 1.7730 - val_accuracy: 0.3744\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.7733 - accuracy: 0.3685 - val_loss: 1.7659 - val_accuracy: 0.3706\n",
            "\n",
            "the best val_acc:\n",
            "0.3968999981880188\n",
            "the model's hyperparameters:\n",
            "256\n",
            "512\n",
            "0.08512988272634009\n",
            "0.38289668175817587\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/50\n",
            "196/196 - 1s - loss: 2.1756 - accuracy: 0.2607 - val_loss: 2.0230 - val_accuracy: 0.2731\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 1s - loss: 1.8990 - accuracy: 0.3240 - val_loss: 1.7978 - val_accuracy: 0.3545\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 1s - loss: 1.8356 - accuracy: 0.3488 - val_loss: 1.7099 - val_accuracy: 0.3936\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 1s - loss: 1.7680 - accuracy: 0.3714 - val_loss: 1.6680 - val_accuracy: 0.4142\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 1s - loss: 1.7196 - accuracy: 0.3897 - val_loss: 1.6110 - val_accuracy: 0.4267\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 1s - loss: 1.6843 - accuracy: 0.4032 - val_loss: 1.5914 - val_accuracy: 0.4343\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 1s - loss: 1.6532 - accuracy: 0.4129 - val_loss: 1.6872 - val_accuracy: 0.4079\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 1s - loss: 1.6304 - accuracy: 0.4223 - val_loss: 1.6918 - val_accuracy: 0.3737\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 1s - loss: 1.6152 - accuracy: 0.4316 - val_loss: 1.5865 - val_accuracy: 0.4336\n",
            "\n",
            "the best val_acc:\n",
            "0.4343000054359436\n",
            "the model's hyperparameters:\n",
            "256\n",
            "1024\n",
            "0.3440719950944908\n",
            "0.12987198132770106\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.1679 - accuracy: 0.2641 - val_loss: 1.9794 - val_accuracy: 0.2956\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.9180 - accuracy: 0.3197 - val_loss: 1.8188 - val_accuracy: 0.3488\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8321 - accuracy: 0.3484 - val_loss: 1.7275 - val_accuracy: 0.3817\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.8013 - accuracy: 0.3586 - val_loss: 1.7563 - val_accuracy: 0.3615\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7996 - accuracy: 0.3598 - val_loss: 1.7678 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.7805 - accuracy: 0.3681 - val_loss: 1.7043 - val_accuracy: 0.4054\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.7732 - accuracy: 0.3744 - val_loss: 1.6802 - val_accuracy: 0.4040\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.7721 - accuracy: 0.3726 - val_loss: 1.7378 - val_accuracy: 0.3733\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.7534 - accuracy: 0.3765 - val_loss: 1.7024 - val_accuracy: 0.3837\n",
            "\n",
            "the best val_acc:\n",
            "0.40540000796318054\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.38772107685330065\n",
            "0.10886366508465367\n",
            "swish\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            " 11%|█         | 11/100 [05:07<36:54, 24.88s/it, best loss: -0.451200008392334]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc8fd68>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc8fd68>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc8fd68>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc8fd68>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 3s - loss: 2.3200 - accuracy: 0.2559 - val_loss: 1.8221 - val_accuracy: 0.3330\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.9194 - accuracy: 0.3109 - val_loss: 1.7313 - val_accuracy: 0.3782\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8232 - accuracy: 0.3470 - val_loss: 1.7437 - val_accuracy: 0.3572\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7599 - accuracy: 0.3704 - val_loss: 1.6425 - val_accuracy: 0.4116\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7146 - accuracy: 0.3886 - val_loss: 1.6061 - val_accuracy: 0.4334\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.6710 - accuracy: 0.4036 - val_loss: 1.5773 - val_accuracy: 0.4326\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.6439 - accuracy: 0.4134 - val_loss: 1.5626 - val_accuracy: 0.4450\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.6263 - accuracy: 0.4200 - val_loss: 1.5431 - val_accuracy: 0.4610\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6166 - accuracy: 0.4255 - val_loss: 1.5344 - val_accuracy: 0.4528\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.5958 - accuracy: 0.4290 - val_loss: 1.5248 - val_accuracy: 0.4544\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.5853 - accuracy: 0.4359 - val_loss: 1.5305 - val_accuracy: 0.4565\n",
            "\n",
            "the best val_acc:\n",
            "0.460999995470047\n",
            "the model's hyperparameters:\n",
            "256\n",
            "1024\n",
            "0.1427536323932737\n",
            "0.2685614728598054\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.2166 - accuracy: 0.2768 - val_loss: 1.9170 - val_accuracy: 0.2996\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.8902 - accuracy: 0.3315 - val_loss: 1.7032 - val_accuracy: 0.4015\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.7992 - accuracy: 0.3633 - val_loss: 1.7701 - val_accuracy: 0.3620\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7639 - accuracy: 0.3724 - val_loss: 1.7385 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7368 - accuracy: 0.3820 - val_loss: 1.6786 - val_accuracy: 0.4058\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.7150 - accuracy: 0.3923 - val_loss: 1.6564 - val_accuracy: 0.4169\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.7116 - accuracy: 0.3926 - val_loss: 1.6831 - val_accuracy: 0.4055\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.7038 - accuracy: 0.3976 - val_loss: 1.7444 - val_accuracy: 0.3655\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6879 - accuracy: 0.4014 - val_loss: 1.6270 - val_accuracy: 0.4223\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.6713 - accuracy: 0.4084 - val_loss: 1.6609 - val_accuracy: 0.3973\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.6588 - accuracy: 0.4116 - val_loss: 1.6380 - val_accuracy: 0.4325\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 3s - loss: 1.6608 - accuracy: 0.4118 - val_loss: 1.6062 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 3s - loss: 1.6500 - accuracy: 0.4157 - val_loss: 1.6319 - val_accuracy: 0.4152\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 3s - loss: 1.6314 - accuracy: 0.4244 - val_loss: 1.5852 - val_accuracy: 0.4230\n",
            "\n",
            "the best val_acc:\n",
            "0.4325000047683716\n",
            "the model's hyperparameters:\n",
            "512\n",
            "256\n",
            "0.0695227040297906\n",
            "0.3802005950535183\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            "196/196 - 2s - loss: 4.3478 - accuracy: 0.1511 - val_loss: 2.7148 - val_accuracy: 0.1798\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.7399 - accuracy: 0.1768 - val_loss: 3.0484 - val_accuracy: 0.2018\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 2.4168 - accuracy: 0.2058 - val_loss: 2.5009 - val_accuracy: 0.1806\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 2.2383 - accuracy: 0.2314 - val_loss: 2.1248 - val_accuracy: 0.2566\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 2.0935 - accuracy: 0.2617 - val_loss: 2.1596 - val_accuracy: 0.2273\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 2.0151 - accuracy: 0.2869 - val_loss: 2.0329 - val_accuracy: 0.2696\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.9713 - accuracy: 0.2978 - val_loss: 1.8992 - val_accuracy: 0.3092\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.9249 - accuracy: 0.3123 - val_loss: 1.9526 - val_accuracy: 0.2911\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.9060 - accuracy: 0.3223 - val_loss: 1.9101 - val_accuracy: 0.3205\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.8790 - accuracy: 0.3341 - val_loss: 1.9021 - val_accuracy: 0.3005\n",
            "\n",
            "Epoch 11/50\n",
            "196/196 - 2s - loss: 1.8708 - accuracy: 0.3346 - val_loss: 1.7836 - val_accuracy: 0.3636\n",
            "\n",
            "Epoch 12/50\n",
            "196/196 - 2s - loss: 1.8494 - accuracy: 0.3464 - val_loss: 1.8487 - val_accuracy: 0.3376\n",
            "\n",
            "Epoch 13/50\n",
            "196/196 - 2s - loss: 1.8386 - accuracy: 0.3478 - val_loss: 1.9041 - val_accuracy: 0.3480\n",
            "\n",
            "Epoch 14/50\n",
            "196/196 - 2s - loss: 1.8279 - accuracy: 0.3564 - val_loss: 1.8234 - val_accuracy: 0.3589\n",
            "\n",
            "the best val_acc:\n",
            "0.3635999858379364\n",
            "the model's hyperparameters:\n",
            "512\n",
            "512\n",
            "0.39572993542756807\n",
            "0.24774418507814583\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.3795 - accuracy: 0.2413 - val_loss: 1.8235 - val_accuracy: 0.3532\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 2.0053 - accuracy: 0.2965 - val_loss: 1.8016 - val_accuracy: 0.3451\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8924 - accuracy: 0.3282 - val_loss: 1.7520 - val_accuracy: 0.3686\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.8171 - accuracy: 0.3522 - val_loss: 1.7273 - val_accuracy: 0.3848\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7756 - accuracy: 0.3689 - val_loss: 1.6712 - val_accuracy: 0.4160\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.7558 - accuracy: 0.3735 - val_loss: 1.6704 - val_accuracy: 0.4142\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.7454 - accuracy: 0.3795 - val_loss: 1.6355 - val_accuracy: 0.4290\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.7414 - accuracy: 0.3826 - val_loss: 1.6435 - val_accuracy: 0.4240\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.7285 - accuracy: 0.3851 - val_loss: 1.6365 - val_accuracy: 0.4282\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.7224 - accuracy: 0.3869 - val_loss: 1.6274 - val_accuracy: 0.4220\n",
            "\n",
            "the best val_acc:\n",
            "0.42899999022483826\n",
            "the model's hyperparameters:\n",
            "512\n",
            "256\n",
            "0.07444360343627376\n",
            "0.07162917162162163\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 15%|█▌        | 15/100 [07:16<41:24, 29.23s/it, best loss: -0.460999995470047]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503942dcc0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503942dcc0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503942dcc0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503942dcc0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 1.9980 - accuracy: 0.2983 - val_loss: 1.7928 - val_accuracy: 0.3407\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.7602 - accuracy: 0.3709 - val_loss: 1.6965 - val_accuracy: 0.3953\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.6765 - accuracy: 0.3971 - val_loss: 1.6307 - val_accuracy: 0.4179\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 4s - loss: 1.6303 - accuracy: 0.4168 - val_loss: 1.5576 - val_accuracy: 0.4485\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 4s - loss: 1.5947 - accuracy: 0.4310 - val_loss: 1.5455 - val_accuracy: 0.4452\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 4s - loss: 1.5753 - accuracy: 0.4391 - val_loss: 1.5118 - val_accuracy: 0.4617\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 4s - loss: 1.5491 - accuracy: 0.4453 - val_loss: 1.5704 - val_accuracy: 0.4371\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.5352 - accuracy: 0.4530 - val_loss: 1.5207 - val_accuracy: 0.4570\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.5123 - accuracy: 0.4621 - val_loss: 1.5094 - val_accuracy: 0.4629\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.4940 - accuracy: 0.4673 - val_loss: 1.5216 - val_accuracy: 0.4690\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 4s - loss: 1.4813 - accuracy: 0.4713 - val_loss: 1.4887 - val_accuracy: 0.4777\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 4s - loss: 1.4645 - accuracy: 0.4806 - val_loss: 1.4876 - val_accuracy: 0.4823\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.4517 - accuracy: 0.4836 - val_loss: 1.5119 - val_accuracy: 0.4699\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 4s - loss: 1.4338 - accuracy: 0.4896 - val_loss: 1.5163 - val_accuracy: 0.4660\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 4s - loss: 1.4272 - accuracy: 0.4903 - val_loss: 1.5151 - val_accuracy: 0.4645\n",
            "\n",
            "the best val_acc:\n",
            "0.4823000133037567\n",
            "the model's hyperparameters:\n",
            "512\n",
            "512\n",
            "0.37974831678729387\n",
            "0.2403674476197581\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            "782/782 - 5s - loss: 2.1721 - accuracy: 0.1833 - val_loss: 1.9735 - val_accuracy: 0.2455\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 2.0993 - accuracy: 0.2000 - val_loss: 2.0133 - val_accuracy: 0.2395\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 2.0768 - accuracy: 0.2043 - val_loss: 1.9594 - val_accuracy: 0.2709\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 2.0534 - accuracy: 0.2178 - val_loss: 1.9540 - val_accuracy: 0.2846\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 2.0469 - accuracy: 0.2170 - val_loss: 2.0338 - val_accuracy: 0.2426\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 2.0422 - accuracy: 0.2166 - val_loss: 1.9242 - val_accuracy: 0.2812\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 2.0475 - accuracy: 0.2149 - val_loss: 1.9314 - val_accuracy: 0.2638\n",
            "\n",
            "the best val_acc:\n",
            "0.28459998965263367\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "512\n",
            "0.22414604610911326\n",
            "0.40101033232032784\n",
            "swish\n",
            "rmsprop\n",
            "128\n",
            "Epoch 1/50\n",
            " 17%|█▋        | 17/100 [09:01<54:25, 39.35s/it, best loss: -0.4823000133037567]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc261d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc261d0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc261d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503dc261d0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 3s - loss: 3.8570 - accuracy: 0.1695 - val_loss: 2.1607 - val_accuracy: 0.2144\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 2.0555 - accuracy: 0.2663 - val_loss: 1.8688 - val_accuracy: 0.3146\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8709 - accuracy: 0.3283 - val_loss: 1.7503 - val_accuracy: 0.3609\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7816 - accuracy: 0.3634 - val_loss: 1.7534 - val_accuracy: 0.3622\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7295 - accuracy: 0.3861 - val_loss: 1.6597 - val_accuracy: 0.4101\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.6977 - accuracy: 0.3974 - val_loss: 1.8304 - val_accuracy: 0.3707\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.6653 - accuracy: 0.4097 - val_loss: 1.5673 - val_accuracy: 0.4488\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.6412 - accuracy: 0.4167 - val_loss: 1.5852 - val_accuracy: 0.4382\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6131 - accuracy: 0.4271 - val_loss: 1.5987 - val_accuracy: 0.4321\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.5958 - accuracy: 0.4355 - val_loss: 1.5786 - val_accuracy: 0.4373\n",
            "\n",
            "the best val_acc:\n",
            "0.4487999975681305\n",
            "the model's hyperparameters:\n",
            "512\n",
            "1024\n",
            "0.4440995372232807\n",
            "0.19378913952416787\n",
            "swish\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            " 18%|█▊        | 18/100 [09:35<51:27, 37.66s/it, best loss: -0.4823000133037567]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503ddce9b0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503ddce9b0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503ddce9b0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f503ddce9b0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "196/196 - 2s - loss: 4.9074 - accuracy: 0.1506 - val_loss: 2.2918 - val_accuracy: 0.2317\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.4088 - accuracy: 0.1966 - val_loss: 2.1980 - val_accuracy: 0.2091\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 2.1033 - accuracy: 0.2466 - val_loss: 2.0115 - val_accuracy: 0.2650\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.9529 - accuracy: 0.2937 - val_loss: 1.9107 - val_accuracy: 0.3068\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 1.8816 - accuracy: 0.3234 - val_loss: 1.8913 - val_accuracy: 0.3148\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.8256 - accuracy: 0.3481 - val_loss: 1.7835 - val_accuracy: 0.3635\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.7934 - accuracy: 0.3592 - val_loss: 1.8682 - val_accuracy: 0.3283\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.7642 - accuracy: 0.3703 - val_loss: 1.7697 - val_accuracy: 0.3493\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.7440 - accuracy: 0.3793 - val_loss: 1.7681 - val_accuracy: 0.3605\n",
            "\n",
            "the best val_acc:\n",
            "0.3634999990463257\n",
            "the model's hyperparameters:\n",
            "256\n",
            "256\n",
            "0.4793083914304218\n",
            "0.4113277286717177\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 2s - loss: 2.1991 - accuracy: 0.2355 - val_loss: 1.8845 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 2s - loss: 2.0043 - accuracy: 0.2861 - val_loss: 1.8264 - val_accuracy: 0.3474\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 2s - loss: 1.9197 - accuracy: 0.3137 - val_loss: 1.7735 - val_accuracy: 0.3759\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 2s - loss: 1.8690 - accuracy: 0.3310 - val_loss: 1.7399 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 2s - loss: 1.8465 - accuracy: 0.3422 - val_loss: 1.7347 - val_accuracy: 0.3701\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 2s - loss: 1.8334 - accuracy: 0.3474 - val_loss: 1.7237 - val_accuracy: 0.3876\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 2s - loss: 1.8181 - accuracy: 0.3507 - val_loss: 1.7247 - val_accuracy: 0.3912\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 2s - loss: 1.8077 - accuracy: 0.3566 - val_loss: 1.7011 - val_accuracy: 0.3952\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 2s - loss: 1.7940 - accuracy: 0.3625 - val_loss: 1.6827 - val_accuracy: 0.4058\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 2s - loss: 1.7812 - accuracy: 0.3662 - val_loss: 1.6684 - val_accuracy: 0.4114\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 2s - loss: 1.7621 - accuracy: 0.3712 - val_loss: 1.6736 - val_accuracy: 0.4037\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 2s - loss: 1.7631 - accuracy: 0.3739 - val_loss: 1.6579 - val_accuracy: 0.4156\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 2s - loss: 1.7510 - accuracy: 0.3803 - val_loss: 1.6768 - val_accuracy: 0.4075\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 2s - loss: 1.7404 - accuracy: 0.3812 - val_loss: 1.6508 - val_accuracy: 0.4175\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 2s - loss: 1.7313 - accuracy: 0.3875 - val_loss: 1.6183 - val_accuracy: 0.4259\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 2s - loss: 1.7262 - accuracy: 0.3881 - val_loss: 1.6638 - val_accuracy: 0.4130\n",
            "\n",
            "Epoch 17/50\n",
            "391/391 - 2s - loss: 1.7187 - accuracy: 0.3916 - val_loss: 1.6256 - val_accuracy: 0.4266\n",
            "\n",
            "Epoch 18/50\n",
            "391/391 - 2s - loss: 1.7103 - accuracy: 0.3914 - val_loss: 1.6110 - val_accuracy: 0.4200\n",
            "\n",
            "Epoch 19/50\n",
            "391/391 - 2s - loss: 1.7048 - accuracy: 0.3941 - val_loss: 1.6599 - val_accuracy: 0.4065\n",
            "\n",
            "Epoch 20/50\n",
            "391/391 - 2s - loss: 1.7110 - accuracy: 0.3956 - val_loss: 1.6391 - val_accuracy: 0.4140\n",
            "\n",
            "the best val_acc:\n",
            "0.42660000920295715\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.29818576362256294\n",
            "0.027428539564151935\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 20%|██        | 20/100 [10:42<49:24, 37.06s/it, best loss: -0.4823000133037567]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032f8c5f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032f8c5f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032f8c5f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032f8c5f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 2.1904 - accuracy: 0.2700 - val_loss: 1.8292 - val_accuracy: 0.3249\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8622 - accuracy: 0.3287 - val_loss: 1.7051 - val_accuracy: 0.3859\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7783 - accuracy: 0.3562 - val_loss: 1.7218 - val_accuracy: 0.3699\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7239 - accuracy: 0.3800 - val_loss: 1.6393 - val_accuracy: 0.4073\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6822 - accuracy: 0.3961 - val_loss: 1.6015 - val_accuracy: 0.4224\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6585 - accuracy: 0.4036 - val_loss: 1.5833 - val_accuracy: 0.4287\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 6s - loss: 1.6448 - accuracy: 0.4093 - val_loss: 1.5944 - val_accuracy: 0.4265\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6234 - accuracy: 0.4195 - val_loss: 1.5906 - val_accuracy: 0.4414\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6105 - accuracy: 0.4268 - val_loss: 1.5740 - val_accuracy: 0.4343\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6055 - accuracy: 0.4275 - val_loss: 1.5490 - val_accuracy: 0.4445\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.5928 - accuracy: 0.4323 - val_loss: 1.5352 - val_accuracy: 0.4582\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.5761 - accuracy: 0.4371 - val_loss: 1.5223 - val_accuracy: 0.4747\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.5674 - accuracy: 0.4389 - val_loss: 1.4858 - val_accuracy: 0.4750\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5573 - accuracy: 0.4447 - val_loss: 1.5564 - val_accuracy: 0.4597\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5464 - accuracy: 0.4475 - val_loss: 1.5099 - val_accuracy: 0.4687\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.5331 - accuracy: 0.4546 - val_loss: 1.4906 - val_accuracy: 0.4701\n",
            "\n",
            "the best val_acc:\n",
            "0.4749999940395355\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.2795605465417399\n",
            "0.012428967606855822\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 21%|██        | 21/100 [12:08<1:08:22, 51.93s/it, best loss: -0.4823000133037567]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032b25908>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032b25908>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032b25908>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f5032b25908>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 2.1293 - accuracy: 0.2721 - val_loss: 1.8064 - val_accuracy: 0.3487\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8519 - accuracy: 0.3363 - val_loss: 1.7170 - val_accuracy: 0.3811\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7591 - accuracy: 0.3658 - val_loss: 1.6431 - val_accuracy: 0.4109\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7145 - accuracy: 0.3851 - val_loss: 1.5997 - val_accuracy: 0.4309\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6745 - accuracy: 0.3998 - val_loss: 1.5969 - val_accuracy: 0.4273\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6539 - accuracy: 0.4093 - val_loss: 1.5813 - val_accuracy: 0.4406\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6407 - accuracy: 0.4153 - val_loss: 1.5709 - val_accuracy: 0.4466\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6268 - accuracy: 0.4165 - val_loss: 1.5795 - val_accuracy: 0.4465\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6143 - accuracy: 0.4218 - val_loss: 1.5353 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.5965 - accuracy: 0.4290 - val_loss: 1.5521 - val_accuracy: 0.4492\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.5840 - accuracy: 0.4356 - val_loss: 1.5410 - val_accuracy: 0.4506\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.5722 - accuracy: 0.4376 - val_loss: 1.5232 - val_accuracy: 0.4566\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.5588 - accuracy: 0.4440 - val_loss: 1.5006 - val_accuracy: 0.4577\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5542 - accuracy: 0.4446 - val_loss: 1.5155 - val_accuracy: 0.4672\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5484 - accuracy: 0.4466 - val_loss: 1.4992 - val_accuracy: 0.4693\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.5342 - accuracy: 0.4479 - val_loss: 1.4942 - val_accuracy: 0.4675\n",
            "\n",
            "Epoch 17/50\n",
            "782/782 - 5s - loss: 1.5256 - accuracy: 0.4538 - val_loss: 1.5308 - val_accuracy: 0.4467\n",
            "\n",
            "Epoch 18/50\n",
            "782/782 - 5s - loss: 1.5190 - accuracy: 0.4569 - val_loss: 1.4901 - val_accuracy: 0.4752\n",
            "\n",
            "Epoch 19/50\n",
            "782/782 - 5s - loss: 1.5090 - accuracy: 0.4620 - val_loss: 1.4926 - val_accuracy: 0.4746\n",
            "\n",
            "Epoch 20/50\n",
            "782/782 - 5s - loss: 1.4975 - accuracy: 0.4659 - val_loss: 1.4856 - val_accuracy: 0.4774\n",
            "\n",
            "Epoch 21/50\n",
            "782/782 - 5s - loss: 1.4921 - accuracy: 0.4672 - val_loss: 1.4775 - val_accuracy: 0.4824\n",
            "\n",
            "Epoch 22/50\n",
            "782/782 - 5s - loss: 1.4856 - accuracy: 0.4665 - val_loss: 1.4728 - val_accuracy: 0.4811\n",
            "\n",
            "Epoch 23/50\n",
            "782/782 - 5s - loss: 1.4707 - accuracy: 0.4748 - val_loss: 1.5335 - val_accuracy: 0.4640\n",
            "\n",
            "Epoch 24/50\n",
            "782/782 - 5s - loss: 1.4679 - accuracy: 0.4747 - val_loss: 1.4806 - val_accuracy: 0.4710\n",
            "\n",
            "the best val_acc:\n",
            "0.48240000009536743\n",
            "the model's hyperparameters:\n",
            "512\n",
            "256\n",
            "0.17681785356096003\n",
            "0.010464147852943709\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            "782/782 - 5s - loss: 2.0595 - accuracy: 0.2404 - val_loss: 1.9081 - val_accuracy: 0.2731\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 4s - loss: 1.9493 - accuracy: 0.2741 - val_loss: 1.8016 - val_accuracy: 0.3450\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 4s - loss: 1.9130 - accuracy: 0.2902 - val_loss: 1.8294 - val_accuracy: 0.3380\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.8928 - accuracy: 0.2994 - val_loss: 1.8274 - val_accuracy: 0.3535\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 4s - loss: 1.8754 - accuracy: 0.3077 - val_loss: 1.7983 - val_accuracy: 0.3506\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 4s - loss: 1.8731 - accuracy: 0.3108 - val_loss: 1.7723 - val_accuracy: 0.3663\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 4s - loss: 1.8656 - accuracy: 0.3143 - val_loss: 1.7858 - val_accuracy: 0.3565\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 4s - loss: 1.8531 - accuracy: 0.3149 - val_loss: 1.7785 - val_accuracy: 0.3554\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 4s - loss: 1.8476 - accuracy: 0.3199 - val_loss: 1.8109 - val_accuracy: 0.3374\n",
            "\n",
            "the best val_acc:\n",
            "0.36629998683929443\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.2568397856841742\n",
            "0.06441887886521691\n",
            "swish\n",
            "sgd\n",
            "64\n",
            "Epoch 1/50\n",
            " 23%|██▎       | 23/100 [15:01<1:23:57, 65.43s/it, best loss: -0.48240000009536743]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b77c588>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b77c588>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b77c588>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b77c588>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 1.9660 - accuracy: 0.2950 - val_loss: 1.9012 - val_accuracy: 0.3286\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8341 - accuracy: 0.3564 - val_loss: 1.7770 - val_accuracy: 0.3791\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7989 - accuracy: 0.3688 - val_loss: 1.8275 - val_accuracy: 0.3634\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7772 - accuracy: 0.3807 - val_loss: 1.8196 - val_accuracy: 0.3551\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.7611 - accuracy: 0.3853 - val_loss: 1.8080 - val_accuracy: 0.3624\n",
            "\n",
            "the best val_acc:\n",
            "0.3790999948978424\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.2809592567709636\n",
            "0.06870426719716338\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 24%|██▍       | 24/100 [15:26<1:07:39, 53.42s/it, best loss: -0.48240000009536743]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50329c6470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50329c6470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50329c6470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50329c6470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 6s - loss: 2.1147 - accuracy: 0.2764 - val_loss: 1.8172 - val_accuracy: 0.3562\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8545 - accuracy: 0.3342 - val_loss: 1.7691 - val_accuracy: 0.3474\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7603 - accuracy: 0.3689 - val_loss: 1.6972 - val_accuracy: 0.3911\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7154 - accuracy: 0.3860 - val_loss: 1.6215 - val_accuracy: 0.4150\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6829 - accuracy: 0.3992 - val_loss: 1.6200 - val_accuracy: 0.4236\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6642 - accuracy: 0.4034 - val_loss: 1.6044 - val_accuracy: 0.4328\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6518 - accuracy: 0.4092 - val_loss: 1.5912 - val_accuracy: 0.4367\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6296 - accuracy: 0.4182 - val_loss: 1.5893 - val_accuracy: 0.4373\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6178 - accuracy: 0.4210 - val_loss: 1.5501 - val_accuracy: 0.4508\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6074 - accuracy: 0.4257 - val_loss: 1.5458 - val_accuracy: 0.4404\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 6s - loss: 1.5938 - accuracy: 0.4322 - val_loss: 1.5373 - val_accuracy: 0.4500\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 6s - loss: 1.5851 - accuracy: 0.4336 - val_loss: 1.5339 - val_accuracy: 0.4544\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.5723 - accuracy: 0.4358 - val_loss: 1.5547 - val_accuracy: 0.4492\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5518 - accuracy: 0.4480 - val_loss: 1.5421 - val_accuracy: 0.4464\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5478 - accuracy: 0.4494 - val_loss: 1.5094 - val_accuracy: 0.4695\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.5370 - accuracy: 0.4505 - val_loss: 1.5048 - val_accuracy: 0.4692\n",
            "\n",
            "Epoch 17/50\n",
            "782/782 - 5s - loss: 1.5318 - accuracy: 0.4541 - val_loss: 1.5559 - val_accuracy: 0.4421\n",
            "\n",
            "Epoch 18/50\n",
            "782/782 - 5s - loss: 1.5225 - accuracy: 0.4558 - val_loss: 1.5116 - val_accuracy: 0.4655\n",
            "\n",
            "the best val_acc:\n",
            "0.46950000524520874\n",
            "the model's hyperparameters:\n",
            "512\n",
            "256\n",
            "0.18627566703814286\n",
            "0.05394945272082607\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 25%|██▌       | 25/100 [17:05<1:23:55, 67.14s/it, best loss: -0.48240000009536743]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bc5f860>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bc5f860>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bc5f860>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bc5f860>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 2.0323 - accuracy: 0.2850 - val_loss: 1.7476 - val_accuracy: 0.3680\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8065 - accuracy: 0.3504 - val_loss: 1.6783 - val_accuracy: 0.3938\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 4s - loss: 1.7279 - accuracy: 0.3774 - val_loss: 1.6540 - val_accuracy: 0.4095\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.6819 - accuracy: 0.3962 - val_loss: 1.6816 - val_accuracy: 0.3797\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6454 - accuracy: 0.4087 - val_loss: 1.5827 - val_accuracy: 0.4403\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6425 - accuracy: 0.4091 - val_loss: 1.6128 - val_accuracy: 0.4321\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 4s - loss: 1.6232 - accuracy: 0.4204 - val_loss: 1.5718 - val_accuracy: 0.4394\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 4s - loss: 1.6031 - accuracy: 0.4231 - val_loss: 1.5626 - val_accuracy: 0.4445\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.5875 - accuracy: 0.4319 - val_loss: 1.5444 - val_accuracy: 0.4489\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.5689 - accuracy: 0.4377 - val_loss: 1.5343 - val_accuracy: 0.4556\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 4s - loss: 1.5562 - accuracy: 0.4436 - val_loss: 1.5572 - val_accuracy: 0.4455\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.5438 - accuracy: 0.4476 - val_loss: 1.5188 - val_accuracy: 0.4644\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 4s - loss: 1.5358 - accuracy: 0.4499 - val_loss: 1.4883 - val_accuracy: 0.4700\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5198 - accuracy: 0.4525 - val_loss: 1.5193 - val_accuracy: 0.4589\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5085 - accuracy: 0.4628 - val_loss: 1.5258 - val_accuracy: 0.4581\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.5057 - accuracy: 0.4604 - val_loss: 1.5162 - val_accuracy: 0.4633\n",
            "\n",
            "the best val_acc:\n",
            "0.4699999988079071\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.028073437261085993\n",
            "0.004680693563967516\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            "782/782 - 6s - loss: 1.9506 - accuracy: 0.3016 - val_loss: 1.8059 - val_accuracy: 0.3216\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.7817 - accuracy: 0.3534 - val_loss: 1.7770 - val_accuracy: 0.3395\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7342 - accuracy: 0.3765 - val_loss: 1.6898 - val_accuracy: 0.3945\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7066 - accuracy: 0.3877 - val_loss: 1.7346 - val_accuracy: 0.3818\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6931 - accuracy: 0.3900 - val_loss: 1.6612 - val_accuracy: 0.4010\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6738 - accuracy: 0.3993 - val_loss: 1.6540 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6630 - accuracy: 0.4036 - val_loss: 1.6405 - val_accuracy: 0.4130\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6553 - accuracy: 0.4079 - val_loss: 1.6279 - val_accuracy: 0.4237\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6411 - accuracy: 0.4094 - val_loss: 1.6191 - val_accuracy: 0.4139\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6406 - accuracy: 0.4096 - val_loss: 1.6028 - val_accuracy: 0.4333\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.6338 - accuracy: 0.4145 - val_loss: 1.6151 - val_accuracy: 0.4220\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.6212 - accuracy: 0.4189 - val_loss: 1.6192 - val_accuracy: 0.4252\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.6137 - accuracy: 0.4192 - val_loss: 1.6160 - val_accuracy: 0.4215\n",
            "\n",
            "the best val_acc:\n",
            "0.4332999885082245\n",
            "the model's hyperparameters:\n",
            "512\n",
            "256\n",
            "0.1328968231912633\n",
            "0.10243477517634067\n",
            "swish\n",
            "sgd\n",
            "64\n",
            "Epoch 1/50\n",
            " 27%|██▋       | 27/100 [19:32<1:25:14, 70.06s/it, best loss: -0.48240000009536743]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b8d5eb8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b8d5eb8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b8d5eb8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502b8d5eb8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 4s - loss: 1.9594 - accuracy: 0.2944 - val_loss: 1.8833 - val_accuracy: 0.3296\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 4s - loss: 1.8359 - accuracy: 0.3553 - val_loss: 1.8262 - val_accuracy: 0.3631\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 4s - loss: 1.7975 - accuracy: 0.3703 - val_loss: 1.7990 - val_accuracy: 0.3635\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 4s - loss: 1.7799 - accuracy: 0.3771 - val_loss: 1.8573 - val_accuracy: 0.3341\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 4s - loss: 1.7612 - accuracy: 0.3845 - val_loss: 1.8293 - val_accuracy: 0.3630\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 4s - loss: 1.7475 - accuracy: 0.3890 - val_loss: 1.7490 - val_accuracy: 0.3807\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 4s - loss: 1.7350 - accuracy: 0.3944 - val_loss: 1.7089 - val_accuracy: 0.3995\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 4s - loss: 1.7210 - accuracy: 0.3982 - val_loss: 1.8043 - val_accuracy: 0.3606\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 4s - loss: 1.7094 - accuracy: 0.4013 - val_loss: 1.7916 - val_accuracy: 0.3698\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 4s - loss: 1.6978 - accuracy: 0.4057 - val_loss: 1.6763 - val_accuracy: 0.4073\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 4s - loss: 1.6869 - accuracy: 0.4105 - val_loss: 1.7618 - val_accuracy: 0.3616\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 4s - loss: 1.6758 - accuracy: 0.4150 - val_loss: 1.6568 - val_accuracy: 0.4127\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 4s - loss: 1.6672 - accuracy: 0.4152 - val_loss: 1.7379 - val_accuracy: 0.3890\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 4s - loss: 1.6566 - accuracy: 0.4212 - val_loss: 1.6528 - val_accuracy: 0.4200\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 4s - loss: 1.6450 - accuracy: 0.4238 - val_loss: 1.6742 - val_accuracy: 0.4224\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 4s - loss: 1.6396 - accuracy: 0.4290 - val_loss: 1.6494 - val_accuracy: 0.4179\n",
            "\n",
            "Epoch 17/50\n",
            "782/782 - 4s - loss: 1.6356 - accuracy: 0.4279 - val_loss: 1.6767 - val_accuracy: 0.4098\n",
            "\n",
            "Epoch 18/50\n",
            "782/782 - 4s - loss: 1.6254 - accuracy: 0.4330 - val_loss: 1.6450 - val_accuracy: 0.4194\n",
            "\n",
            "the best val_acc:\n",
            "0.42239999771118164\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.01279433060353763\n",
            "0.1677163639894852\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 28%|██▊       | 28/100 [20:49<1:26:37, 72.18s/it, best loss: -0.48240000009536743]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50392badd8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50392badd8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50392badd8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f50392badd8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 6s - loss: 2.0340 - accuracy: 0.3047 - val_loss: 1.9040 - val_accuracy: 0.3395\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.7720 - accuracy: 0.3633 - val_loss: 1.7325 - val_accuracy: 0.3929\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.6720 - accuracy: 0.4003 - val_loss: 1.6755 - val_accuracy: 0.3931\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.5954 - accuracy: 0.4294 - val_loss: 1.6166 - val_accuracy: 0.4244\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.5602 - accuracy: 0.4450 - val_loss: 1.5687 - val_accuracy: 0.4472\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.5323 - accuracy: 0.4516 - val_loss: 1.5271 - val_accuracy: 0.4554\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.4968 - accuracy: 0.4658 - val_loss: 1.4994 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.4754 - accuracy: 0.4726 - val_loss: 1.4990 - val_accuracy: 0.4751\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 6s - loss: 1.4530 - accuracy: 0.4834 - val_loss: 1.4481 - val_accuracy: 0.4884\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 6s - loss: 1.4290 - accuracy: 0.4897 - val_loss: 1.4793 - val_accuracy: 0.4730\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.4140 - accuracy: 0.4942 - val_loss: 1.4722 - val_accuracy: 0.4718\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.3953 - accuracy: 0.5002 - val_loss: 1.4902 - val_accuracy: 0.4637\n",
            "\n",
            "the best val_acc:\n",
            "0.48840001225471497\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.024128996511624524\n",
            "0.331218187633204\n",
            "swish\n",
            "sgd\n",
            "64\n",
            "Epoch 1/50\n",
            " 29%|██▉       | 29/100 [21:55<1:23:25, 70.50s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bbb1c88>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bbb1c88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bbb1c88>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f502bbb1c88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 1.9489 - accuracy: 0.3019 - val_loss: 1.8736 - val_accuracy: 0.3096\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8294 - accuracy: 0.3578 - val_loss: 1.9357 - val_accuracy: 0.3036\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7957 - accuracy: 0.3695 - val_loss: 1.9268 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7727 - accuracy: 0.3794 - val_loss: 1.7903 - val_accuracy: 0.3755\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.7592 - accuracy: 0.3854 - val_loss: 1.8329 - val_accuracy: 0.3485\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.7439 - accuracy: 0.3930 - val_loss: 1.7611 - val_accuracy: 0.3835\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.7313 - accuracy: 0.3973 - val_loss: 1.7306 - val_accuracy: 0.3918\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.7190 - accuracy: 0.4016 - val_loss: 1.7758 - val_accuracy: 0.3684\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.7084 - accuracy: 0.4047 - val_loss: 1.7955 - val_accuracy: 0.3573\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6914 - accuracy: 0.4102 - val_loss: 1.6936 - val_accuracy: 0.3962\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.6783 - accuracy: 0.4142 - val_loss: 1.6782 - val_accuracy: 0.4127\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.6658 - accuracy: 0.4183 - val_loss: 1.8463 - val_accuracy: 0.3283\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.6563 - accuracy: 0.4221 - val_loss: 1.6653 - val_accuracy: 0.4180\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.6463 - accuracy: 0.4256 - val_loss: 1.6678 - val_accuracy: 0.4168\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.6357 - accuracy: 0.4294 - val_loss: 1.7359 - val_accuracy: 0.3798\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.6272 - accuracy: 0.4313 - val_loss: 1.6809 - val_accuracy: 0.4077\n",
            "\n",
            "the best val_acc:\n",
            "0.4180000126361847\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.0004655550425354104\n",
            "0.1607935092809453\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            "782/782 - 6s - loss: 1.9682 - accuracy: 0.3063 - val_loss: 1.7663 - val_accuracy: 0.3566\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.7821 - accuracy: 0.3577 - val_loss: 1.8174 - val_accuracy: 0.3481\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7357 - accuracy: 0.3748 - val_loss: 1.7300 - val_accuracy: 0.3763\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7064 - accuracy: 0.3847 - val_loss: 1.7114 - val_accuracy: 0.3904\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6924 - accuracy: 0.3920 - val_loss: 1.7200 - val_accuracy: 0.3741\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6685 - accuracy: 0.4043 - val_loss: 1.6906 - val_accuracy: 0.3887\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6611 - accuracy: 0.4055 - val_loss: 1.6619 - val_accuracy: 0.3970\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6533 - accuracy: 0.4053 - val_loss: 1.6582 - val_accuracy: 0.4035\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6381 - accuracy: 0.4147 - val_loss: 1.6413 - val_accuracy: 0.4123\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6252 - accuracy: 0.4170 - val_loss: 1.6262 - val_accuracy: 0.4162\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.6248 - accuracy: 0.4171 - val_loss: 1.6281 - val_accuracy: 0.4177\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.6131 - accuracy: 0.4220 - val_loss: 1.6421 - val_accuracy: 0.4044\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.6078 - accuracy: 0.4243 - val_loss: 1.6627 - val_accuracy: 0.3997\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.6038 - accuracy: 0.4254 - val_loss: 1.6431 - val_accuracy: 0.4092\n",
            "\n",
            "the best val_acc:\n",
            "0.41769999265670776\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.23361844740020232\n",
            "0.3254991679766601\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 31%|███       | 31/100 [24:30<1:25:02, 73.95s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd76e198>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd76e198>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd76e198>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd76e198>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 6s - loss: 2.1690 - accuracy: 0.2611 - val_loss: 1.8561 - val_accuracy: 0.3160\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8632 - accuracy: 0.3286 - val_loss: 1.7801 - val_accuracy: 0.3600\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7748 - accuracy: 0.3626 - val_loss: 1.6563 - val_accuracy: 0.4125\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7271 - accuracy: 0.3804 - val_loss: 1.6182 - val_accuracy: 0.4255\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.7005 - accuracy: 0.3891 - val_loss: 1.6367 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6804 - accuracy: 0.3976 - val_loss: 1.6013 - val_accuracy: 0.4305\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6652 - accuracy: 0.4027 - val_loss: 1.5858 - val_accuracy: 0.4288\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6504 - accuracy: 0.4091 - val_loss: 1.6025 - val_accuracy: 0.4282\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6354 - accuracy: 0.4148 - val_loss: 1.5944 - val_accuracy: 0.4413\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6264 - accuracy: 0.4174 - val_loss: 1.5634 - val_accuracy: 0.4435\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.6145 - accuracy: 0.4219 - val_loss: 1.5651 - val_accuracy: 0.4479\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.6113 - accuracy: 0.4234 - val_loss: 1.5658 - val_accuracy: 0.4449\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.5989 - accuracy: 0.4284 - val_loss: 1.5507 - val_accuracy: 0.4501\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5887 - accuracy: 0.4343 - val_loss: 1.5853 - val_accuracy: 0.4196\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5860 - accuracy: 0.4331 - val_loss: 1.5522 - val_accuracy: 0.4410\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.5732 - accuracy: 0.4399 - val_loss: 1.5550 - val_accuracy: 0.4414\n",
            "\n",
            "the best val_acc:\n",
            "0.45010000467300415\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.18543911947766467\n",
            "0.2922561274367771\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 32%|███▏      | 32/100 [25:57<1:28:12, 77.83s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd610fd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd610fd0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd610fd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd610fd0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 6s - loss: 2.1061 - accuracy: 0.2746 - val_loss: 2.0366 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8372 - accuracy: 0.3391 - val_loss: 1.7589 - val_accuracy: 0.3537\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7461 - accuracy: 0.3717 - val_loss: 1.6991 - val_accuracy: 0.3918\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.6892 - accuracy: 0.3958 - val_loss: 1.6187 - val_accuracy: 0.4190\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6573 - accuracy: 0.4090 - val_loss: 1.6489 - val_accuracy: 0.4054\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6414 - accuracy: 0.4150 - val_loss: 1.5682 - val_accuracy: 0.4452\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6209 - accuracy: 0.4216 - val_loss: 1.5351 - val_accuracy: 0.4543\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6031 - accuracy: 0.4282 - val_loss: 1.5486 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.5904 - accuracy: 0.4307 - val_loss: 1.5382 - val_accuracy: 0.4496\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 6s - loss: 1.5664 - accuracy: 0.4408 - val_loss: 1.4942 - val_accuracy: 0.4671\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 6s - loss: 1.5551 - accuracy: 0.4441 - val_loss: 1.5614 - val_accuracy: 0.4378\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.5436 - accuracy: 0.4477 - val_loss: 1.5537 - val_accuracy: 0.4463\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.5304 - accuracy: 0.4528 - val_loss: 1.4957 - val_accuracy: 0.4748\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5166 - accuracy: 0.4585 - val_loss: 1.5411 - val_accuracy: 0.4561\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5151 - accuracy: 0.4597 - val_loss: 1.5233 - val_accuracy: 0.4585\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.4939 - accuracy: 0.4686 - val_loss: 1.4761 - val_accuracy: 0.4780\n",
            "\n",
            "Epoch 17/50\n",
            "782/782 - 5s - loss: 1.4822 - accuracy: 0.4752 - val_loss: 1.4981 - val_accuracy: 0.4635\n",
            "\n",
            "Epoch 18/50\n",
            "782/782 - 5s - loss: 1.4700 - accuracy: 0.4770 - val_loss: 1.4940 - val_accuracy: 0.4747\n",
            "\n",
            "Epoch 19/50\n",
            "782/782 - 5s - loss: 1.4746 - accuracy: 0.4748 - val_loss: 1.4888 - val_accuracy: 0.4758\n",
            "\n",
            "the best val_acc:\n",
            "0.4779999852180481\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.4400961883896076\n",
            "0.1828248331260907\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            "782/782 - 6s - loss: 2.1720 - accuracy: 0.1904 - val_loss: 2.0436 - val_accuracy: 0.2388\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 2.0861 - accuracy: 0.2059 - val_loss: 1.9231 - val_accuracy: 0.2722\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 2.0582 - accuracy: 0.2160 - val_loss: 1.9968 - val_accuracy: 0.2474\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 2.0471 - accuracy: 0.2196 - val_loss: 1.9204 - val_accuracy: 0.2832\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 2.0332 - accuracy: 0.2312 - val_loss: 1.9435 - val_accuracy: 0.2922\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 2.0308 - accuracy: 0.2325 - val_loss: 1.9220 - val_accuracy: 0.2826\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 2.0241 - accuracy: 0.2328 - val_loss: 1.8992 - val_accuracy: 0.2891\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 6s - loss: 2.0209 - accuracy: 0.2344 - val_loss: 1.8987 - val_accuracy: 0.2863\n",
            "\n",
            "the best val_acc:\n",
            "0.2921999990940094\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.27861675020483434\n",
            "0.2170762123002116\n",
            "swish\n",
            "sgd\n",
            "64\n",
            "Epoch 1/50\n",
            " 34%|███▍      | 34/100 [28:26<1:20:43, 73.39s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd82b00f0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd82b00f0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd82b00f0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd82b00f0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 1.9735 - accuracy: 0.2884 - val_loss: 1.9450 - val_accuracy: 0.2888\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8455 - accuracy: 0.3496 - val_loss: 1.8521 - val_accuracy: 0.3363\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.8093 - accuracy: 0.3644 - val_loss: 1.8138 - val_accuracy: 0.3506\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7871 - accuracy: 0.3732 - val_loss: 1.8080 - val_accuracy: 0.3635\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.7738 - accuracy: 0.3805 - val_loss: 1.7650 - val_accuracy: 0.3798\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.7618 - accuracy: 0.3857 - val_loss: 1.9344 - val_accuracy: 0.3130\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.7511 - accuracy: 0.3926 - val_loss: 1.8189 - val_accuracy: 0.3520\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.7474 - accuracy: 0.3893 - val_loss: 1.8140 - val_accuracy: 0.3541\n",
            "\n",
            "the best val_acc:\n",
            "0.3797999918460846\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.3157972699862448\n",
            "0.030199658761039586\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 35%|███▌      | 35/100 [29:05<1:08:32, 63.27s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd798bd30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd798bd30>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd798bd30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd798bd30>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 6s - loss: 2.1394 - accuracy: 0.2690 - val_loss: 1.8444 - val_accuracy: 0.3438\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8574 - accuracy: 0.3310 - val_loss: 1.7187 - val_accuracy: 0.3826\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.7716 - accuracy: 0.3627 - val_loss: 1.6645 - val_accuracy: 0.3976\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7224 - accuracy: 0.3817 - val_loss: 1.6221 - val_accuracy: 0.4238\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.6984 - accuracy: 0.3941 - val_loss: 1.6260 - val_accuracy: 0.4175\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.6749 - accuracy: 0.3964 - val_loss: 1.5811 - val_accuracy: 0.4272\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.6558 - accuracy: 0.4069 - val_loss: 1.6063 - val_accuracy: 0.4186\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.6552 - accuracy: 0.4067 - val_loss: 1.5702 - val_accuracy: 0.4398\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.6416 - accuracy: 0.4114 - val_loss: 1.5497 - val_accuracy: 0.4433\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.6254 - accuracy: 0.4181 - val_loss: 1.5521 - val_accuracy: 0.4481\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.6107 - accuracy: 0.4238 - val_loss: 1.5524 - val_accuracy: 0.4504\n",
            "\n",
            "Epoch 12/50\n",
            "782/782 - 5s - loss: 1.6000 - accuracy: 0.4239 - val_loss: 1.5537 - val_accuracy: 0.4582\n",
            "\n",
            "Epoch 13/50\n",
            "782/782 - 5s - loss: 1.5877 - accuracy: 0.4343 - val_loss: 1.5617 - val_accuracy: 0.4392\n",
            "\n",
            "Epoch 14/50\n",
            "782/782 - 5s - loss: 1.5847 - accuracy: 0.4343 - val_loss: 1.5253 - val_accuracy: 0.4592\n",
            "\n",
            "Epoch 15/50\n",
            "782/782 - 5s - loss: 1.5708 - accuracy: 0.4399 - val_loss: 1.5479 - val_accuracy: 0.4433\n",
            "\n",
            "Epoch 16/50\n",
            "782/782 - 5s - loss: 1.5722 - accuracy: 0.4390 - val_loss: 1.5307 - val_accuracy: 0.4499\n",
            "\n",
            "Epoch 17/50\n",
            "782/782 - 5s - loss: 1.5599 - accuracy: 0.4413 - val_loss: 1.5016 - val_accuracy: 0.4765\n",
            "\n",
            "Epoch 18/50\n",
            "782/782 - 5s - loss: 1.5524 - accuracy: 0.4454 - val_loss: 1.5087 - val_accuracy: 0.4655\n",
            "\n",
            "Epoch 19/50\n",
            "782/782 - 5s - loss: 1.5486 - accuracy: 0.4478 - val_loss: 1.5055 - val_accuracy: 0.4712\n",
            "\n",
            "Epoch 20/50\n",
            "782/782 - 5s - loss: 1.5362 - accuracy: 0.4521 - val_loss: 1.5073 - val_accuracy: 0.4673\n",
            "\n",
            "the best val_acc:\n",
            "0.476500004529953\n",
            "the model's hyperparameters:\n",
            "256\n",
            "256\n",
            "0.2645973183414081\n",
            "0.29978339814954236\n",
            "swish\n",
            "rmsprop\n",
            "64\n",
            "Epoch 1/50\n",
            " 36%|███▌      | 36/100 [30:54<1:21:52, 76.76s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f28fd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f28fd0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f28fd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f28fd0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 2.2501 - accuracy: 0.2370 - val_loss: 1.9761 - val_accuracy: 0.2627\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8892 - accuracy: 0.3177 - val_loss: 1.7781 - val_accuracy: 0.3470\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.8050 - accuracy: 0.3498 - val_loss: 1.7833 - val_accuracy: 0.3327\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.7580 - accuracy: 0.3684 - val_loss: 1.8698 - val_accuracy: 0.3352\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.7252 - accuracy: 0.3828 - val_loss: 1.7984 - val_accuracy: 0.3457\n",
            "\n",
            "the best val_acc:\n",
            "0.34700000286102295\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "512\n",
            "0.14411587565326073\n",
            "0.4731207035614941\n",
            "swish\n",
            "sgd\n",
            "64\n",
            "Epoch 1/50\n",
            " 37%|███▋      | 37/100 [31:19<1:04:12, 61.15s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f315c0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f315c0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f315c0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6f315c0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 2.0152 - accuracy: 0.2732 - val_loss: 1.8588 - val_accuracy: 0.3366\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.8787 - accuracy: 0.3326 - val_loss: 1.8631 - val_accuracy: 0.3152\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.8398 - accuracy: 0.3521 - val_loss: 1.9518 - val_accuracy: 0.2889\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.8204 - accuracy: 0.3574 - val_loss: 1.9978 - val_accuracy: 0.2968\n",
            "\n",
            "the best val_acc:\n",
            "0.33660000562667847\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.326203336640562\n",
            "0.09782775060649884\n",
            "relu\n",
            "adam\n",
            "256\n",
            "Epoch 1/50\n",
            "196/196 - 2s - loss: 2.3248 - accuracy: 0.1931 - val_loss: 1.9427 - val_accuracy: 0.2749\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.0361 - accuracy: 0.2238 - val_loss: 1.9435 - val_accuracy: 0.2624\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 2.0267 - accuracy: 0.2299 - val_loss: 1.8722 - val_accuracy: 0.3090\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 2.0137 - accuracy: 0.2377 - val_loss: 1.9182 - val_accuracy: 0.2966\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 2.0098 - accuracy: 0.2372 - val_loss: 1.8825 - val_accuracy: 0.3009\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 2.0069 - accuracy: 0.2365 - val_loss: 1.8759 - val_accuracy: 0.3157\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 2.0051 - accuracy: 0.2405 - val_loss: 1.9014 - val_accuracy: 0.2999\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.9992 - accuracy: 0.2420 - val_loss: 1.9288 - val_accuracy: 0.3168\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.9889 - accuracy: 0.2497 - val_loss: 1.8621 - val_accuracy: 0.3072\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.9959 - accuracy: 0.2443 - val_loss: 1.8869 - val_accuracy: 0.2972\n",
            "\n",
            "Epoch 11/50\n",
            "196/196 - 2s - loss: 1.9939 - accuracy: 0.2467 - val_loss: 1.9442 - val_accuracy: 0.2888\n",
            "\n",
            "the best val_acc:\n",
            "0.31679999828338623\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "256\n",
            "0.4335317639677443\n",
            "0.14018388079896682\n",
            "swish\n",
            "adam\n",
            "64\n",
            "Epoch 1/50\n",
            " 39%|███▉      | 39/100 [32:08<43:12, 42.51s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fadf67be0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fadf67be0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fadf67be0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fadf67be0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "782/782 - 5s - loss: 2.2834 - accuracy: 0.2353 - val_loss: 1.8047 - val_accuracy: 0.3610\n",
            "\n",
            "Epoch 2/50\n",
            "782/782 - 5s - loss: 1.9184 - accuracy: 0.3038 - val_loss: 1.7806 - val_accuracy: 0.3585\n",
            "\n",
            "Epoch 3/50\n",
            "782/782 - 5s - loss: 1.8590 - accuracy: 0.3264 - val_loss: 1.7372 - val_accuracy: 0.3839\n",
            "\n",
            "Epoch 4/50\n",
            "782/782 - 5s - loss: 1.8298 - accuracy: 0.3388 - val_loss: 1.7252 - val_accuracy: 0.3838\n",
            "\n",
            "Epoch 5/50\n",
            "782/782 - 5s - loss: 1.8090 - accuracy: 0.3513 - val_loss: 1.6807 - val_accuracy: 0.3957\n",
            "\n",
            "Epoch 6/50\n",
            "782/782 - 5s - loss: 1.7997 - accuracy: 0.3528 - val_loss: 1.6744 - val_accuracy: 0.4066\n",
            "\n",
            "Epoch 7/50\n",
            "782/782 - 5s - loss: 1.7892 - accuracy: 0.3589 - val_loss: 1.6914 - val_accuracy: 0.3982\n",
            "\n",
            "Epoch 8/50\n",
            "782/782 - 5s - loss: 1.7749 - accuracy: 0.3646 - val_loss: 1.6421 - val_accuracy: 0.4292\n",
            "\n",
            "Epoch 9/50\n",
            "782/782 - 5s - loss: 1.7724 - accuracy: 0.3659 - val_loss: 1.6779 - val_accuracy: 0.4109\n",
            "\n",
            "Epoch 10/50\n",
            "782/782 - 5s - loss: 1.7682 - accuracy: 0.3690 - val_loss: 1.6802 - val_accuracy: 0.4027\n",
            "\n",
            "Epoch 11/50\n",
            "782/782 - 5s - loss: 1.7600 - accuracy: 0.3701 - val_loss: 1.6738 - val_accuracy: 0.3861\n",
            "\n",
            "the best val_acc:\n",
            "0.4291999936103821\n",
            "the model's hyperparameters:\n",
            "256\n",
            "512\n",
            "0.21080345894358254\n",
            "0.4520086759579889\n",
            "swish\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            " 40%|████      | 40/100 [33:06<47:29, 47.49s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4faddf3470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4faddf3470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4faddf3470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4faddf3470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "196/196 - 2s - loss: 3.0948 - accuracy: 0.1650 - val_loss: 2.6754 - val_accuracy: 0.1115\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 2.1106 - accuracy: 0.2400 - val_loss: 1.9289 - val_accuracy: 0.3052\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 1.9687 - accuracy: 0.2881 - val_loss: 1.7900 - val_accuracy: 0.3530\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.8840 - accuracy: 0.3212 - val_loss: 1.8720 - val_accuracy: 0.3234\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 1.8451 - accuracy: 0.3389 - val_loss: 1.8284 - val_accuracy: 0.3441\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.8059 - accuracy: 0.3525 - val_loss: 1.7749 - val_accuracy: 0.3622\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.7796 - accuracy: 0.3662 - val_loss: 1.8093 - val_accuracy: 0.3642\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.7585 - accuracy: 0.3714 - val_loss: 1.8164 - val_accuracy: 0.3374\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.7337 - accuracy: 0.3793 - val_loss: 1.7915 - val_accuracy: 0.3637\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.7174 - accuracy: 0.3904 - val_loss: 1.6977 - val_accuracy: 0.3746\n",
            "\n",
            "Epoch 11/50\n",
            "196/196 - 2s - loss: 1.6941 - accuracy: 0.4009 - val_loss: 1.6395 - val_accuracy: 0.4079\n",
            "\n",
            "Epoch 12/50\n",
            "196/196 - 2s - loss: 1.6831 - accuracy: 0.4002 - val_loss: 1.7136 - val_accuracy: 0.3879\n",
            "\n",
            "Epoch 13/50\n",
            "196/196 - 2s - loss: 1.6701 - accuracy: 0.4079 - val_loss: 1.6894 - val_accuracy: 0.3980\n",
            "\n",
            "Epoch 14/50\n",
            "196/196 - 2s - loss: 1.6569 - accuracy: 0.4126 - val_loss: 1.6059 - val_accuracy: 0.4302\n",
            "\n",
            "Epoch 15/50\n",
            "196/196 - 2s - loss: 1.6435 - accuracy: 0.4147 - val_loss: 1.6394 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 16/50\n",
            "196/196 - 2s - loss: 1.6357 - accuracy: 0.4215 - val_loss: 1.7762 - val_accuracy: 0.3772\n",
            "\n",
            "Epoch 17/50\n",
            "196/196 - 2s - loss: 1.6264 - accuracy: 0.4250 - val_loss: 1.6215 - val_accuracy: 0.4146\n",
            "\n",
            "the best val_acc:\n",
            "0.4302000105381012\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.3623552778311364\n",
            "0.12117465276172931\n",
            "swish\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            " 41%|████      | 41/100 [33:38<42:03, 42.77s/it, best loss: -0.48840001225471497]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd93fda0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd93fda0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd93fda0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fdd93fda0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 3s - loss: 2.5139 - accuracy: 0.2720 - val_loss: 1.8908 - val_accuracy: 0.3148\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.9069 - accuracy: 0.3211 - val_loss: 1.8182 - val_accuracy: 0.3380\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8390 - accuracy: 0.3443 - val_loss: 1.7089 - val_accuracy: 0.3920\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7753 - accuracy: 0.3656 - val_loss: 1.7517 - val_accuracy: 0.3639\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7200 - accuracy: 0.3830 - val_loss: 1.6762 - val_accuracy: 0.4030\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.6647 - accuracy: 0.4064 - val_loss: 1.6009 - val_accuracy: 0.4238\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.6438 - accuracy: 0.4136 - val_loss: 1.6263 - val_accuracy: 0.4241\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.6340 - accuracy: 0.4131 - val_loss: 1.5840 - val_accuracy: 0.4380\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6167 - accuracy: 0.4209 - val_loss: 1.5439 - val_accuracy: 0.4522\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.6006 - accuracy: 0.4278 - val_loss: 1.5285 - val_accuracy: 0.4460\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.5905 - accuracy: 0.4323 - val_loss: 1.5329 - val_accuracy: 0.4630\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 3s - loss: 1.5769 - accuracy: 0.4364 - val_loss: 1.5499 - val_accuracy: 0.4591\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 3s - loss: 1.5753 - accuracy: 0.4397 - val_loss: 1.5035 - val_accuracy: 0.4564\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 3s - loss: 1.5538 - accuracy: 0.4452 - val_loss: 1.5069 - val_accuracy: 0.4710\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 3s - loss: 1.5564 - accuracy: 0.4462 - val_loss: 1.4864 - val_accuracy: 0.4683\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 3s - loss: 1.5352 - accuracy: 0.4511 - val_loss: 1.4873 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 17/50\n",
            "391/391 - 3s - loss: 1.5321 - accuracy: 0.4536 - val_loss: 1.4822 - val_accuracy: 0.4785\n",
            "\n",
            "Epoch 18/50\n",
            "391/391 - 3s - loss: 1.5287 - accuracy: 0.4551 - val_loss: 1.4935 - val_accuracy: 0.4647\n",
            "\n",
            "Epoch 19/50\n",
            "391/391 - 3s - loss: 1.5229 - accuracy: 0.4555 - val_loss: 1.4648 - val_accuracy: 0.4793\n",
            "\n",
            "Epoch 20/50\n",
            "391/391 - 3s - loss: 1.5147 - accuracy: 0.4585 - val_loss: 1.4841 - val_accuracy: 0.4626\n",
            "\n",
            "Epoch 21/50\n",
            "391/391 - 3s - loss: 1.5013 - accuracy: 0.4619 - val_loss: 1.4515 - val_accuracy: 0.4783\n",
            "\n",
            "Epoch 22/50\n",
            "391/391 - 3s - loss: 1.4969 - accuracy: 0.4668 - val_loss: 1.4652 - val_accuracy: 0.4794\n",
            "\n",
            "Epoch 23/50\n",
            "391/391 - 3s - loss: 1.4859 - accuracy: 0.4711 - val_loss: 1.4528 - val_accuracy: 0.4937\n",
            "\n",
            "Epoch 24/50\n",
            "391/391 - 3s - loss: 1.4769 - accuracy: 0.4735 - val_loss: 1.4542 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 25/50\n",
            "391/391 - 3s - loss: 1.4802 - accuracy: 0.4715 - val_loss: 1.4735 - val_accuracy: 0.4755\n",
            "\n",
            "Epoch 26/50\n",
            "391/391 - 3s - loss: 1.4680 - accuracy: 0.4777 - val_loss: 1.4639 - val_accuracy: 0.4910\n",
            "\n",
            "the best val_acc:\n",
            "0.4936999976634979\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.49276287024565263\n",
            "0.17480785800449467\n",
            "relu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.0389 - accuracy: 0.2689 - val_loss: 1.8220 - val_accuracy: 0.3644\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 2s - loss: 1.8571 - accuracy: 0.3373 - val_loss: 1.7329 - val_accuracy: 0.3971\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.7898 - accuracy: 0.3656 - val_loss: 1.6875 - val_accuracy: 0.4076\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7448 - accuracy: 0.3802 - val_loss: 1.6524 - val_accuracy: 0.4341\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 2s - loss: 1.7071 - accuracy: 0.3965 - val_loss: 1.6255 - val_accuracy: 0.4376\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 2s - loss: 1.6795 - accuracy: 0.4085 - val_loss: 1.6175 - val_accuracy: 0.4358\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 2s - loss: 1.6570 - accuracy: 0.4137 - val_loss: 1.6019 - val_accuracy: 0.4392\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 2s - loss: 1.6345 - accuracy: 0.4197 - val_loss: 1.5598 - val_accuracy: 0.4531\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6128 - accuracy: 0.4298 - val_loss: 1.5481 - val_accuracy: 0.4577\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.5968 - accuracy: 0.4342 - val_loss: 1.5231 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.5836 - accuracy: 0.4408 - val_loss: 1.5222 - val_accuracy: 0.4578\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 3s - loss: 1.5718 - accuracy: 0.4434 - val_loss: 1.5288 - val_accuracy: 0.4558\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 3s - loss: 1.5568 - accuracy: 0.4489 - val_loss: 1.5335 - val_accuracy: 0.4591\n",
            "\n",
            "the best val_acc:\n",
            "0.46889999508857727\n",
            "the model's hyperparameters:\n",
            "256\n",
            "1024\n",
            "0.3643395018413008\n",
            "0.21033903106896717\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.2180 - accuracy: 0.2531 - val_loss: 1.9513 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.9438 - accuracy: 0.3085 - val_loss: 1.7955 - val_accuracy: 0.3589\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8591 - accuracy: 0.3374 - val_loss: 1.7581 - val_accuracy: 0.3615\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.8411 - accuracy: 0.3428 - val_loss: 1.7878 - val_accuracy: 0.3477\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.8450 - accuracy: 0.3428 - val_loss: 1.7787 - val_accuracy: 0.3619\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.8271 - accuracy: 0.3529 - val_loss: 1.8140 - val_accuracy: 0.3619\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.8310 - accuracy: 0.3529 - val_loss: 1.7938 - val_accuracy: 0.3617\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.8203 - accuracy: 0.3568 - val_loss: 1.7514 - val_accuracy: 0.3606\n",
            "\n",
            "the best val_acc:\n",
            "0.3619000017642975\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.47290923076523955\n",
            "0.12275060652838875\n",
            "swish\n",
            "rmsprop\n",
            "128\n",
            "Epoch 1/50\n",
            " 44%|████▍     | 44/100 [35:55<37:42, 40.41s/it, best loss: -0.4936999976634979]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fad969080>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fad969080>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fad969080>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fad969080>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 4s - loss: 6.5879 - accuracy: 0.1525 - val_loss: 2.3092 - val_accuracy: 0.1908\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 4s - loss: 2.1520 - accuracy: 0.2393 - val_loss: 2.0574 - val_accuracy: 0.2668\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 4s - loss: 1.9097 - accuracy: 0.3074 - val_loss: 1.9452 - val_accuracy: 0.3075\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 4s - loss: 1.8323 - accuracy: 0.3368 - val_loss: 1.7892 - val_accuracy: 0.3631\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 4s - loss: 1.7867 - accuracy: 0.3597 - val_loss: 1.6810 - val_accuracy: 0.3906\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 4s - loss: 1.7555 - accuracy: 0.3744 - val_loss: 1.6600 - val_accuracy: 0.3937\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 4s - loss: 1.7283 - accuracy: 0.3833 - val_loss: 1.6064 - val_accuracy: 0.4417\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 4s - loss: 1.7015 - accuracy: 0.3937 - val_loss: 1.6195 - val_accuracy: 0.4155\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 4s - loss: 1.6814 - accuracy: 0.4008 - val_loss: 1.6087 - val_accuracy: 0.4151\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 4s - loss: 1.6590 - accuracy: 0.4081 - val_loss: 1.5551 - val_accuracy: 0.4475\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 4s - loss: 1.6439 - accuracy: 0.4127 - val_loss: 1.5799 - val_accuracy: 0.4372\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 4s - loss: 1.6299 - accuracy: 0.4179 - val_loss: 1.5532 - val_accuracy: 0.4382\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 4s - loss: 1.6148 - accuracy: 0.4274 - val_loss: 1.5276 - val_accuracy: 0.4501\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 4s - loss: 1.6034 - accuracy: 0.4296 - val_loss: 1.5517 - val_accuracy: 0.4442\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 3s - loss: 1.5946 - accuracy: 0.4359 - val_loss: 1.5565 - val_accuracy: 0.4410\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 4s - loss: 1.5822 - accuracy: 0.4387 - val_loss: 1.5832 - val_accuracy: 0.4253\n",
            "\n",
            "the best val_acc:\n",
            "0.45010000467300415\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.4129652985295237\n",
            "0.23254231123735736\n",
            "swish\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            " 45%|████▌     | 45/100 [36:54<42:16, 46.12s/it, best loss: -0.4936999976634979]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6c5b4a8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6c5b4a8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6c5b4a8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4fd6c5b4a8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 3s - loss: 2.6060 - accuracy: 0.2517 - val_loss: 1.9147 - val_accuracy: 0.3190\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 1.9473 - accuracy: 0.3074 - val_loss: 1.8621 - val_accuracy: 0.3495\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8692 - accuracy: 0.3317 - val_loss: 1.7509 - val_accuracy: 0.3563\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.7994 - accuracy: 0.3572 - val_loss: 1.6669 - val_accuracy: 0.3980\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7372 - accuracy: 0.3780 - val_loss: 1.6220 - val_accuracy: 0.4231\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.6984 - accuracy: 0.3933 - val_loss: 1.5998 - val_accuracy: 0.4363\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.6691 - accuracy: 0.4037 - val_loss: 1.5853 - val_accuracy: 0.4377\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.6476 - accuracy: 0.4138 - val_loss: 1.5878 - val_accuracy: 0.4448\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6370 - accuracy: 0.4137 - val_loss: 1.5428 - val_accuracy: 0.4489\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.6279 - accuracy: 0.4172 - val_loss: 1.5510 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.6199 - accuracy: 0.4186 - val_loss: 1.5294 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 3s - loss: 1.6170 - accuracy: 0.4219 - val_loss: 1.5246 - val_accuracy: 0.4637\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 3s - loss: 1.6148 - accuracy: 0.4239 - val_loss: 1.5248 - val_accuracy: 0.4534\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 3s - loss: 1.6080 - accuracy: 0.4240 - val_loss: 1.5134 - val_accuracy: 0.4655\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 3s - loss: 1.5961 - accuracy: 0.4289 - val_loss: 1.5353 - val_accuracy: 0.4504\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 3s - loss: 1.5906 - accuracy: 0.4320 - val_loss: 1.5277 - val_accuracy: 0.4419\n",
            "\n",
            "Epoch 17/50\n",
            "391/391 - 3s - loss: 1.5836 - accuracy: 0.4336 - val_loss: 1.4966 - val_accuracy: 0.4649\n",
            "\n",
            "the best val_acc:\n",
            "0.46549999713897705\n",
            "the model's hyperparameters:\n",
            "256\n",
            "1024\n",
            "0.05768552377057195\n",
            "0.2621669514494219\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 2s - loss: 2.0993 - accuracy: 0.2819 - val_loss: 1.9428 - val_accuracy: 0.3225\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 2s - loss: 1.8475 - accuracy: 0.3436 - val_loss: 1.7699 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 2s - loss: 1.7631 - accuracy: 0.3743 - val_loss: 1.6974 - val_accuracy: 0.3891\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 2s - loss: 1.7011 - accuracy: 0.3976 - val_loss: 1.7178 - val_accuracy: 0.3821\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 2s - loss: 1.6758 - accuracy: 0.4039 - val_loss: 1.6561 - val_accuracy: 0.4128\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.6584 - accuracy: 0.4103 - val_loss: 1.6615 - val_accuracy: 0.3910\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.6439 - accuracy: 0.4177 - val_loss: 1.5622 - val_accuracy: 0.4548\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.6101 - accuracy: 0.4264 - val_loss: 1.6328 - val_accuracy: 0.4087\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.6049 - accuracy: 0.4310 - val_loss: 1.5423 - val_accuracy: 0.4527\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.5885 - accuracy: 0.4376 - val_loss: 1.6600 - val_accuracy: 0.4106\n",
            "\n",
            "the best val_acc:\n",
            "0.454800009727478\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.35311083022161044\n",
            "0.15710493310315612\n",
            "swish\n",
            "rmsprop\n",
            "128\n",
            "Epoch 1/50\n",
            " 47%|████▋     | 47/100 [38:12<36:26, 41.25s/it, best loss: -0.4936999976634979]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f395de5f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f395de5f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f395de5f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f395de5f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 4s - loss: 8.6001 - accuracy: 0.1470 - val_loss: 2.1527 - val_accuracy: 0.2076\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 4s - loss: 2.0980 - accuracy: 0.2479 - val_loss: 1.9426 - val_accuracy: 0.2715\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 4s - loss: 1.9136 - accuracy: 0.3067 - val_loss: 1.8010 - val_accuracy: 0.3367\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 4s - loss: 1.8370 - accuracy: 0.3397 - val_loss: 1.7445 - val_accuracy: 0.3717\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 4s - loss: 1.7907 - accuracy: 0.3587 - val_loss: 1.6900 - val_accuracy: 0.3947\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 4s - loss: 1.7543 - accuracy: 0.3723 - val_loss: 1.7129 - val_accuracy: 0.3687\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 4s - loss: 1.7284 - accuracy: 0.3840 - val_loss: 1.6436 - val_accuracy: 0.4145\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 4s - loss: 1.7064 - accuracy: 0.3907 - val_loss: 1.6008 - val_accuracy: 0.4173\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 4s - loss: 1.6772 - accuracy: 0.4009 - val_loss: 1.6639 - val_accuracy: 0.3988\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 4s - loss: 1.6570 - accuracy: 0.4070 - val_loss: 1.6718 - val_accuracy: 0.4116\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 4s - loss: 1.6431 - accuracy: 0.4173 - val_loss: 1.5937 - val_accuracy: 0.4266\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 4s - loss: 1.6285 - accuracy: 0.4210 - val_loss: 1.6134 - val_accuracy: 0.4308\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 4s - loss: 1.6139 - accuracy: 0.4278 - val_loss: 1.5702 - val_accuracy: 0.4423\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 4s - loss: 1.5972 - accuracy: 0.4312 - val_loss: 1.5377 - val_accuracy: 0.4521\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 4s - loss: 1.5889 - accuracy: 0.4355 - val_loss: 1.5445 - val_accuracy: 0.4449\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 4s - loss: 1.5815 - accuracy: 0.4396 - val_loss: 1.5989 - val_accuracy: 0.4411\n",
            "\n",
            "Epoch 17/50\n",
            "391/391 - 4s - loss: 1.5717 - accuracy: 0.4425 - val_loss: 1.5720 - val_accuracy: 0.4349\n",
            "\n",
            "the best val_acc:\n",
            "0.45210000872612\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.41814069103308343\n",
            "0.11651680176681506\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            "391/391 - 3s - loss: 2.8468 - accuracy: 0.2458 - val_loss: 1.8872 - val_accuracy: 0.3217\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 2.0959 - accuracy: 0.2839 - val_loss: 1.8647 - val_accuracy: 0.3234\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.9682 - accuracy: 0.3126 - val_loss: 1.7617 - val_accuracy: 0.3630\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.8568 - accuracy: 0.3383 - val_loss: 1.7641 - val_accuracy: 0.3698\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7935 - accuracy: 0.3621 - val_loss: 1.6871 - val_accuracy: 0.4086\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.7718 - accuracy: 0.3689 - val_loss: 1.6896 - val_accuracy: 0.3982\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.7734 - accuracy: 0.3713 - val_loss: 1.6896 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.7647 - accuracy: 0.3755 - val_loss: 1.6947 - val_accuracy: 0.3799\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.7595 - accuracy: 0.3732 - val_loss: 1.7914 - val_accuracy: 0.3521\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.7668 - accuracy: 0.3704 - val_loss: 1.6422 - val_accuracy: 0.4083\n",
            "\n",
            "the best val_acc:\n",
            "0.4088999927043915\n",
            "the model's hyperparameters:\n",
            "256\n",
            "1024\n",
            "0.11806815502025506\n",
            "0.04694766174798204\n",
            "swish\n",
            "sgd\n",
            "128\n",
            "Epoch 1/50\n",
            " 49%|████▉     | 49/100 [39:49<36:53, 43.40s/it, best loss: -0.4936999976634979]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f348d6710>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f348d6710>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f348d6710>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f348d6710>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 2s - loss: 2.0256 - accuracy: 0.2722 - val_loss: 1.9070 - val_accuracy: 0.3302\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 2s - loss: 1.8690 - accuracy: 0.3418 - val_loss: 1.8433 - val_accuracy: 0.3618\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 2s - loss: 1.8202 - accuracy: 0.3616 - val_loss: 1.8315 - val_accuracy: 0.3593\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 2s - loss: 1.7929 - accuracy: 0.3732 - val_loss: 1.7698 - val_accuracy: 0.3837\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 2s - loss: 1.7736 - accuracy: 0.3826 - val_loss: 1.7541 - val_accuracy: 0.3907\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 2s - loss: 1.7594 - accuracy: 0.3883 - val_loss: 1.8440 - val_accuracy: 0.3493\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 2s - loss: 1.7485 - accuracy: 0.3924 - val_loss: 1.7460 - val_accuracy: 0.3886\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 2s - loss: 1.7404 - accuracy: 0.3961 - val_loss: 1.8267 - val_accuracy: 0.3545\n",
            "\n",
            "the best val_acc:\n",
            "0.39070001244544983\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "512\n",
            "0.16633866216316442\n",
            "0.08655924391937006\n",
            "relu\n",
            "adam\n",
            "256\n",
            "Epoch 1/50\n",
            "196/196 - 2s - loss: 2.3074 - accuracy: 0.2466 - val_loss: 1.8791 - val_accuracy: 0.3276\n",
            "\n",
            "Epoch 2/50\n",
            "196/196 - 2s - loss: 1.8898 - accuracy: 0.3124 - val_loss: 1.7856 - val_accuracy: 0.3530\n",
            "\n",
            "Epoch 3/50\n",
            "196/196 - 2s - loss: 1.8571 - accuracy: 0.3236 - val_loss: 1.7383 - val_accuracy: 0.3779\n",
            "\n",
            "Epoch 4/50\n",
            "196/196 - 2s - loss: 1.8345 - accuracy: 0.3311 - val_loss: 1.7485 - val_accuracy: 0.3659\n",
            "\n",
            "Epoch 5/50\n",
            "196/196 - 2s - loss: 1.8304 - accuracy: 0.3337 - val_loss: 1.7506 - val_accuracy: 0.3732\n",
            "\n",
            "Epoch 6/50\n",
            "196/196 - 2s - loss: 1.8179 - accuracy: 0.3337 - val_loss: 1.7150 - val_accuracy: 0.3825\n",
            "\n",
            "Epoch 7/50\n",
            "196/196 - 2s - loss: 1.8055 - accuracy: 0.3427 - val_loss: 1.7205 - val_accuracy: 0.3805\n",
            "\n",
            "Epoch 8/50\n",
            "196/196 - 2s - loss: 1.7986 - accuracy: 0.3441 - val_loss: 1.7368 - val_accuracy: 0.3801\n",
            "\n",
            "Epoch 9/50\n",
            "196/196 - 2s - loss: 1.7871 - accuracy: 0.3518 - val_loss: 1.7067 - val_accuracy: 0.3927\n",
            "\n",
            "Epoch 10/50\n",
            "196/196 - 2s - loss: 1.7816 - accuracy: 0.3491 - val_loss: 1.6772 - val_accuracy: 0.4064\n",
            "\n",
            "Epoch 11/50\n",
            "196/196 - 2s - loss: 1.7688 - accuracy: 0.3547 - val_loss: 1.7039 - val_accuracy: 0.3874\n",
            "\n",
            "Epoch 12/50\n",
            "196/196 - 2s - loss: 1.7647 - accuracy: 0.3583 - val_loss: 1.7105 - val_accuracy: 0.3814\n",
            "\n",
            "Epoch 13/50\n",
            "196/196 - 2s - loss: 1.7597 - accuracy: 0.3596 - val_loss: 1.6722 - val_accuracy: 0.3992\n",
            "\n",
            "the best val_acc:\n",
            "0.40639999508857727\n",
            "the model's hyperparameters:\n",
            "1024\n",
            "1024\n",
            "0.4620861677871163\n",
            "0.35995494249340576\n",
            "swish\n",
            "adam\n",
            "128\n",
            "Epoch 1/50\n",
            " 51%|█████     | 51/100 [40:33<26:44, 32.74s/it, best loss: -0.4936999976634979]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f33e81630>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f33e81630>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f33e81630>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f4f33e81630>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 - 3s - loss: 2.7502 - accuracy: 0.2360 - val_loss: 1.9545 - val_accuracy: 0.2736\n",
            "\n",
            "Epoch 2/50\n",
            "391/391 - 3s - loss: 2.0237 - accuracy: 0.2886 - val_loss: 1.8524 - val_accuracy: 0.3233\n",
            "\n",
            "Epoch 3/50\n",
            "391/391 - 3s - loss: 1.8823 - accuracy: 0.3283 - val_loss: 1.7680 - val_accuracy: 0.3565\n",
            "\n",
            "Epoch 4/50\n",
            "391/391 - 3s - loss: 1.8119 - accuracy: 0.3498 - val_loss: 1.6854 - val_accuracy: 0.4050\n",
            "\n",
            "Epoch 5/50\n",
            "391/391 - 3s - loss: 1.7744 - accuracy: 0.3619 - val_loss: 1.6642 - val_accuracy: 0.4040\n",
            "\n",
            "Epoch 6/50\n",
            "391/391 - 3s - loss: 1.7586 - accuracy: 0.3705 - val_loss: 1.6924 - val_accuracy: 0.3973\n",
            "\n",
            "Epoch 7/50\n",
            "391/391 - 3s - loss: 1.7558 - accuracy: 0.3679 - val_loss: 1.6634 - val_accuracy: 0.4061\n",
            "\n",
            "Epoch 8/50\n",
            "391/391 - 3s - loss: 1.7438 - accuracy: 0.3741 - val_loss: 1.6435 - val_accuracy: 0.3916\n",
            "\n",
            "Epoch 9/50\n",
            "391/391 - 3s - loss: 1.7415 - accuracy: 0.3753 - val_loss: 1.6216 - val_accuracy: 0.4142\n",
            "\n",
            "Epoch 10/50\n",
            "391/391 - 3s - loss: 1.7436 - accuracy: 0.3741 - val_loss: 1.6318 - val_accuracy: 0.4201\n",
            "\n",
            "Epoch 11/50\n",
            "391/391 - 3s - loss: 1.7398 - accuracy: 0.3729 - val_loss: 1.6437 - val_accuracy: 0.3981\n",
            "\n",
            "Epoch 12/50\n",
            "391/391 - 3s - loss: 1.7355 - accuracy: 0.3803 - val_loss: 1.6208 - val_accuracy: 0.4194\n",
            "\n",
            "Epoch 13/50\n",
            "391/391 - 3s - loss: 1.7172 - accuracy: 0.3847 - val_loss: 1.5926 - val_accuracy: 0.4352\n",
            "\n",
            "Epoch 14/50\n",
            "391/391 - 3s - loss: 1.7028 - accuracy: 0.3881 - val_loss: 1.5625 - val_accuracy: 0.4358\n",
            "\n",
            "Epoch 15/50\n",
            "391/391 - 3s - loss: 1.7026 - accuracy: 0.3916 - val_loss: 1.6332 - val_accuracy: 0.4220\n",
            "\n",
            "Epoch 16/50\n",
            "391/391 - 3s - loss: 1.6983 - accuracy: 0.3934 - val_loss: 1.6192 - val_accuracy: 0.4221\n",
            "\n",
            "Epoch 17/50\n",
            "391/391 - 3s - loss: 1.6927 - accuracy: 0.3957 - val_loss: 1.5945 - val_accuracy: 0.4396\n",
            "\n",
            "Epoch 18/50\n",
            "391/391 - 3s - loss: 1.6980 - accuracy: 0.3945 - val_loss: 1.5867 - val_accuracy: 0.4360\n",
            "\n",
            "Epoch 19/50\n",
            "391/391 - 3s - loss: 1.6896 - accuracy: 0.4006 - val_loss: 1.6288 - val_accuracy: 0.4215\n",
            "\n",
            "Epoch 20/50\n",
            "391/391 - 3s - loss: 1.6973 - accuracy: 0.3952 - val_loss: 1.5551 - val_accuracy: 0.4438\n",
            "\n",
            "Epoch 21/50\n",
            "391/391 - 3s - loss: 1.6888 - accuracy: 0.3991 - val_loss: 1.5789 - val_accuracy: 0.4528\n",
            "\n",
            "Epoch 22/50\n",
            "391/391 - 3s - loss: 1.6833 - accuracy: 0.3999 - val_loss: 1.5915 - val_accuracy: 0.4420\n",
            "\n",
            "Epoch 23/50\n",
            "391/391 - 3s - loss: 1.6750 - accuracy: 0.4042 - val_loss: 1.6040 - val_accuracy: 0.4344\n",
            "\n",
            "Epoch 24/50\n",
            "391/391 - 3s - loss: 1.6806 - accuracy: 0.4004 - val_loss: 1.5895 - val_accuracy: 0.4406\n",
            "\n",
            "the best val_acc:\n",
            "0.4528000056743622\n",
            "the model's hyperparameters:\n",
            "512\n",
            "512\n",
            "0.20684424075644892\n",
            "0.19530741264567672\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/50\n",
            " 52%|█████▏    | 52/100 [41:53<36:40, 45.85s/it, best loss: -0.4936999976634979]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2KtIDbqelBx"
      },
      "source": [
        "Printing out the best soulutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "590fHJmMVSQU"
      },
      "source": [
        "x_train, y_train, x_test, y_test = data()\n",
        "print(\"evaulation of the best model:\")\n",
        "print(best_model.evaluate(x_test, y_test))\n",
        "print(\"best model hyperparameters:\")\n",
        "print(best_run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqO-LYt7exkx"
      },
      "source": [
        "We can see the difference:\n",
        "without optimizing: 55% VS with optimizing: 75%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byDzm3Ijmxrk"
      },
      "source": [
        "# Evaulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4JkZsk2m0Hd"
      },
      "source": [
        "Reading the log file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqNRMsszJ6Wh"
      },
      "source": [
        "import pandas\n",
        "hyperas_log = pandas.read_csv('hyperas-cifar10-log.csv', delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1-FyKg9fULC"
      },
      "source": [
        "Let see the best 10 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye6Y-brFI6rm"
      },
      "source": [
        "hyperas_best10 = hyperas_log.sort_values(by=['best_val_acc'], ascending=False).head(n=10)\n",
        "hyperas_best10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQNpdetZfYgK"
      },
      "source": [
        "...and the worst 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCXlpkcPJJ3u"
      },
      "source": [
        "hyperas_worst10 = hyperas_log.sort_values(by=['best_val_acc'], ascending=False).tail(n=10)\n",
        "hyperas_worst10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BlhOoP3moWB"
      },
      "source": [
        "Some context for the given result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPALjE2Jq7z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# all of the data in blue\n",
        "# the best 10 in red\n",
        "# the worst 10 in yellow\n",
        "\n",
        "for hyperparam in ['n_layer1', 'n_layer2', 'n_layer3', 'n_layer4', 'dropout_1', 'dropout_2', 'dropout_3', 'dropout_4', 'n_batch']:\n",
        "  ax1 = hyperas_log.plot(kind='scatter', x=hyperparam, y='best_val_acc')\n",
        "  hyperas_best10.plot(kind='scatter', x=hyperparam, y='best_val_acc', color='red', ax=ax1)\n",
        "  hyperas_worst10.plot(kind='scatter', x=hyperparam, y='best_val_acc', color='yellow', ax=ax1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCixuiPk7hCe"
      },
      "source": [
        "Now the categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kjjOhgjKCbv"
      },
      "source": [
        "plt.scatter(hyperas_log.act, hyperas_log.best_val_acc)\n",
        "plt.scatter(hyperas_best10.act, hyperas_best10.best_val_acc, color='red')\n",
        "plt.scatter(hyperas_worst10.act, hyperas_worst10.best_val_acc, color='yellow')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(hyperas_log.optim, hyperas_log.best_val_acc)\n",
        "plt.scatter(hyperas_best10.optim, hyperas_best10.best_val_acc, color='red')\n",
        "plt.scatter(hyperas_worst10.optim, hyperas_worst10.best_val_acc, color='yellow')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjiP8Kt67cxT"
      },
      "source": [
        "Import seaborn for more visualizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQuTc7_znX-D"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "max_val_acc = hyperas_log.groupby(['n_batch', 'optim']).max()\n",
        "max_val_acc = max_val_acc.unstack()[['best_val_acc']]\n",
        "sns.heatmap(max_val_acc.best_val_acc, annot=True, fmt='.4g');\n",
        "\n",
        "# bug: seaborn cuts off borders, https://github.com/mwaskom/seaborn/issues/1773\n",
        "b, t = plt.ylim() # discover the values for bottom and top\n",
        "b += 0.5 # Add 0.5 to the bottom\n",
        "t -= 0.5 # Subtract 0.5 from the top\n",
        "plt.ylim(b, t) # update the ylim(bottom, top) values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO40w8AHn2cQ"
      },
      "source": [
        "Conclusion: \n",
        "Unfortunately, the Colab collapses during the optimizing around 52 evaluation. The reason for this error is, citing: \"You run out of all of your available RAM.\". In the .csv log file the results can be seen. "
      ]
    }
  ]
}